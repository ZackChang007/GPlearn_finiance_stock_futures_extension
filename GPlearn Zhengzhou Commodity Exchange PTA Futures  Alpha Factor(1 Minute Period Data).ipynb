{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPlearn 1 Minute  Period Data Alpha Factor Generating\n",
    "## What is Alpha Factor?\n",
    "Alpha (α) is a term used in investing to describe an investment strategy's ability to beat the market, or its \"edge.\" Alpha is thus also often referred to as “excess return” or “abnormal rate of return,” which refers to the idea that markets are efficient, and so there is no way to systematically earn returns that exceed the broad market as a whole. Alpha is often used in conjunction with beta (the Greek letter β), which measures the broad market's overall volatility or risk, known as systematic market risk.  \n",
    "\n",
    "Alpha is used in finance as a measure of performance, indicating when a strategy, trader, or portfolio manager has managed to beat the market return over some period. Alpha, often considered the active return on an investment, gauges the performance of an investment against a market index or benchmark that is considered to represent the market’s movement as a whole.  \n",
    "\n",
    "The excess return of an investment relative to the return of a benchmark index is the investment’s alpha. Alpha may be positive or negative and is the result of active investing. Beta, on the other hand, can be earned through passive index investing.(Retrived from https://www.investopedia.com/terms/a/alpha.asp)  \n",
    "\n",
    "Alpha Factor is a mathmatical expression that tries to identify the strategy that can provide information on the future trend of the market. Alpha factor examples can be found on https://www.spglobal.com/marketintelligence/en/solutions/alpha-factor-library.  \n",
    "## What is GPlearn and symbolic transformer?\n",
    "gplearn implements Genetic Programming in Python, with a scikit-learn inspired and compatible API.\n",
    "\n",
    "While Genetic Programming (GP) can be used to perform a very wide variety of tasks, gplearn is purposefully constrained to solving symbolic regression problems. This is motivated by the scikit-learn ethos, of having powerful estimators that are straight-forward to implement.Genetic programming is capable of taking a series of totally random programs, untrained and unaware of any given target function you might have had in mind, and making them breed, mutate and evolve their way towards the truth.\n",
    "\n",
    "Think of genetic programming as a stochastic optimization process. Every time an initial population is conceived, and with every selection and evolution step in the process, random individuals from the current generation are selected to undergo random changes in order to enter the next. You can control this randomness by using the random_state parameter of the estimator.  \n",
    "\n",
    "A symbolic transformer is a supervised transformer that begins by building a population of naive random formulas to represent a relationship. The formulas are represented as tree-like structures with mathematical functions being recursively applied to variables and constants. Each successive generation of programs is then evolved from the one that came before it by selecting the fittest individuals from the population to undergo genetic operations such as crossover, mutation or reproduction. The final population is searched for the fittest individuals with the least correlation to one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T10:56:41.061963Z",
     "start_time": "2022-08-23T10:56:38.164719Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import graphviz\n",
    "\n",
    "from scipy.stats import rankdata\n",
    "import scipy.stats as stats\n",
    "\n",
    "from gplearn import genetic\n",
    "from gplearn.functions import make_function\n",
    "from gplearn.genetic import SymbolicTransformer, SymbolicRegressor\n",
    "from gplearn.fitness import make_fitness\n",
    "\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.model_selection import train_test_split\n",
    "import baostock as bs\n",
    "from ta.volume import VolumeWeightedAveragePrice\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats.mstats import zscore\n",
    "import talib\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "import datetime\n",
    "from numba import jit\n",
    "import scipy.stats as stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import math\n",
    "import cloudpickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T10:59:15.916403Z",
     "start_time": "2022-08-23T10:59:15.875890Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>money</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-06-21 13:55:00</td>\n",
       "      <td>6928.0</td>\n",
       "      <td>6934.0</td>\n",
       "      <td>6926.0</td>\n",
       "      <td>6932.0</td>\n",
       "      <td>2053.0</td>\n",
       "      <td>71143293.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-06-21 13:56:00</td>\n",
       "      <td>6932.0</td>\n",
       "      <td>6934.0</td>\n",
       "      <td>6926.0</td>\n",
       "      <td>6926.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>27922527.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-06-21 13:57:00</td>\n",
       "      <td>6926.0</td>\n",
       "      <td>6932.0</td>\n",
       "      <td>6926.0</td>\n",
       "      <td>6930.0</td>\n",
       "      <td>678.0</td>\n",
       "      <td>23490440.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date    open    high     low   close  volume       money\n",
       "0 2022-06-21 13:55:00  6928.0  6934.0  6926.0  6932.0  2053.0  71143293.0\n",
       "1 2022-06-21 13:56:00  6932.0  6934.0  6926.0  6926.0   806.0  27922527.0\n",
       "2 2022-06-21 13:57:00  6926.0  6932.0  6926.0  6930.0   678.0  23490440.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv('dataset/PTA1分钟历史数据.csv', parse_dates=['date'])\n",
    "\n",
    "data_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T10:59:19.115903Z",
     "start_time": "2022-08-23T10:59:19.086936Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                    date    open    high     low   close   volume        money\n",
       " 7997 2022-07-22 14:57:00  5620.0  5640.0  5620.0  5634.0  10553.0  297137303.0\n",
       " 7998 2022-07-22 14:58:00  5634.0  5640.0  5630.0  5640.0   8149.0  229665983.0\n",
       " 7999 2022-07-22 14:59:00  5640.0  5658.0  5640.0  5648.0  13682.0  386425287.0,\n",
       "                  date    open    high     low   close  volume       money\n",
       " 0 2022-06-21 13:55:00  6928.0  6934.0  6926.0  6932.0  2053.0  71143293.0\n",
       " 1 2022-06-21 13:56:00  6932.0  6934.0  6926.0  6926.0   806.0  27922527.0\n",
       " 2 2022-06-21 13:57:00  6926.0  6932.0  6926.0  6930.0   678.0  23490440.0,\n",
       " date      False\n",
       " open      False\n",
       " high      False\n",
       " low       False\n",
       " close     False\n",
       " volume    False\n",
       " money     False\n",
       " dtype: bool)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields = ['open','close','high','low','volume','money']\n",
    "length = []\n",
    "\n",
    "df = data_df.copy()\n",
    "df.high = df.high.values.astype('float64')\n",
    "df.low = df.low.values.astype('float64')\n",
    "df.close = df.close.values.astype('float64')\n",
    "df.open = df.open.values.astype('float64')\n",
    "df.volume = df.volume.values.astype('float64')\n",
    "df.amount = df.money.values.astype('float64')\n",
    "\n",
    "df.tail(3), df.head(3), df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate The 1 Minute Rate of Return for Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T10:59:20.861890Z",
     "start_time": "2022-08-23T10:59:20.835370Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>money</th>\n",
       "      <th>1_min_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>2022-07-22 14:56:00</td>\n",
       "      <td>5622.0</td>\n",
       "      <td>5624.0</td>\n",
       "      <td>5618.0</td>\n",
       "      <td>5620.0</td>\n",
       "      <td>5419.0</td>\n",
       "      <td>152291963.0</td>\n",
       "      <td>-0.000356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>2022-07-22 14:57:00</td>\n",
       "      <td>5620.0</td>\n",
       "      <td>5640.0</td>\n",
       "      <td>5620.0</td>\n",
       "      <td>5634.0</td>\n",
       "      <td>10553.0</td>\n",
       "      <td>297137303.0</td>\n",
       "      <td>0.002491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>2022-07-22 14:58:00</td>\n",
       "      <td>5634.0</td>\n",
       "      <td>5640.0</td>\n",
       "      <td>5630.0</td>\n",
       "      <td>5640.0</td>\n",
       "      <td>8149.0</td>\n",
       "      <td>229665983.0</td>\n",
       "      <td>0.001065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    date    open    high     low   close   volume  \\\n",
       "7996 2022-07-22 14:56:00  5622.0  5624.0  5618.0  5620.0   5419.0   \n",
       "7997 2022-07-22 14:57:00  5620.0  5640.0  5620.0  5634.0  10553.0   \n",
       "7998 2022-07-22 14:58:00  5634.0  5640.0  5630.0  5640.0   8149.0   \n",
       "\n",
       "            money  1_min_return  \n",
       "7996  152291963.0     -0.000356  \n",
       "7997  297137303.0      0.002491  \n",
       "7998  229665983.0      0.001065  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['1_min_return'] = df.open.pct_change(1).shift(-1)\n",
    "df = df.dropna()\n",
    "\n",
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Training and Testing Datase# 分割训练和测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T10:59:22.567605Z",
     "start_time": "2022-08-23T10:59:22.563318Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# 训练集占比75%，测试集占比25%\n",
    "train_test_split_date = datetime.strptime('2022-7-14', \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T10:59:23.370916Z",
     "start_time": "2022-08-23T10:59:23.346105Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                 date    open    high     low   close  volume       money  \\\n",
       " 0 2022-06-21 13:55:00  6928.0  6934.0  6926.0  6932.0  2053.0  71143293.0   \n",
       " 1 2022-06-21 13:56:00  6932.0  6934.0  6926.0  6926.0   806.0  27922527.0   \n",
       " 2 2022-06-21 13:57:00  6926.0  6932.0  6926.0  6930.0   678.0  23490440.0   \n",
       " \n",
       "    1_min_return  \n",
       " 0      0.000577  \n",
       " 1     -0.000866  \n",
       " 2      0.000578  ,\n",
       "                     date    open    high     low   close  volume        money  \\\n",
       " 5702 2022-07-13 22:57:00  5566.0  5568.0  5560.0  5564.0  5523.0  153649860.0   \n",
       " 5703 2022-07-13 22:58:00  5564.0  5568.0  5560.0  5564.0  5124.0  142549680.0   \n",
       " 5704 2022-07-13 22:59:00  5564.0  5564.0  5542.0  5552.0  8680.0  240985733.0   \n",
       " \n",
       "       1_min_return  \n",
       " 5702     -0.000359  \n",
       " 5703      0.000000  \n",
       " 5704     -0.006470  ,\n",
       " (5705, 8))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data=df[(df.date<train_test_split_date)]\n",
    "train_data=train_data.reset_index(drop=True)\n",
    "\n",
    "train_data.head(3), train_data.tail(3), train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T10:59:49.975081Z",
     "start_time": "2022-08-23T10:59:49.958384Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                 date    open    high     low   close   volume        money  \\\n",
       " 0 2022-07-14 09:00:00  5528.0  5528.0  5486.0  5490.0  23031.0  633506040.0   \n",
       " 1 2022-07-14 09:01:00  5490.0  5504.0  5482.0  5502.0  11864.0  326022720.0   \n",
       " 2 2022-07-14 09:02:00  5502.0  5504.0  5490.0  5496.0   6823.0  187518783.0   \n",
       " \n",
       "    1_min_return  \n",
       " 0     -0.006874  \n",
       " 1      0.002186  \n",
       " 2     -0.001091  ,\n",
       " (2294, 8))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=df[(df.date>=train_test_split_date)]\n",
    "test_data=test_data.reset_index(drop=True)\n",
    "\n",
    "test_data.head(3), test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T11:00:10.605242Z",
     "start_time": "2022-08-23T11:00:10.590910Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[6.92800000e+03, 6.93400000e+03, 6.92600000e+03, 6.93200000e+03,\n",
       "         2.05300000e+03, 7.11432930e+07],\n",
       "        [6.93200000e+03, 6.93400000e+03, 6.92600000e+03, 6.92600000e+03,\n",
       "         8.06000000e+02, 2.79225270e+07],\n",
       "        [6.92600000e+03, 6.93200000e+03, 6.92600000e+03, 6.93000000e+03,\n",
       "         6.78000000e+02, 2.34904400e+07],\n",
       "        ...,\n",
       "        [5.56600000e+03, 5.56800000e+03, 5.56000000e+03, 5.56400000e+03,\n",
       "         5.52300000e+03, 1.53649860e+08],\n",
       "        [5.56400000e+03, 5.56800000e+03, 5.56000000e+03, 5.56400000e+03,\n",
       "         5.12400000e+03, 1.42549680e+08],\n",
       "        [5.56400000e+03, 5.56400000e+03, 5.54200000e+03, 5.55200000e+03,\n",
       "         8.68000000e+03, 2.40985733e+08]]),\n",
       " (5705, 6),\n",
       " array([ 0.00057737, -0.00086555,  0.00057753, ..., -0.00035932,\n",
       "         0.        , -0.00647017]),\n",
       " (5705,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_data.drop(columns=['date','1_min_return']).to_numpy()\n",
    "y_train = train_data['1_min_return'].values\n",
    "\n",
    "X_train, X_train.shape, y_train, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T11:00:42.765741Z",
     "start_time": "2022-08-23T11:00:42.756517Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[5.52800000e+03, 5.52800000e+03, 5.48600000e+03, 5.49000000e+03,\n",
       "         2.30310000e+04, 6.33506040e+08],\n",
       "        [5.49000000e+03, 5.50400000e+03, 5.48200000e+03, 5.50200000e+03,\n",
       "         1.18640000e+04, 3.26022720e+08],\n",
       "        [5.50200000e+03, 5.50400000e+03, 5.49000000e+03, 5.49600000e+03,\n",
       "         6.82300000e+03, 1.87518783e+08],\n",
       "        ...,\n",
       "        [5.62200000e+03, 5.62400000e+03, 5.61800000e+03, 5.62000000e+03,\n",
       "         5.41900000e+03, 1.52291963e+08],\n",
       "        [5.62000000e+03, 5.64000000e+03, 5.62000000e+03, 5.63400000e+03,\n",
       "         1.05530000e+04, 2.97137303e+08],\n",
       "        [5.63400000e+03, 5.64000000e+03, 5.63000000e+03, 5.64000000e+03,\n",
       "         8.14900000e+03, 2.29665983e+08]]),\n",
       " (2294, 6),\n",
       " array([-0.0068741 ,  0.00218579, -0.00109051, ..., -0.00035575,\n",
       "         0.0024911 ,  0.00106496]),\n",
       " (2294,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test_data.drop(columns=['date', '1_min_return']).to_numpy()\n",
    "y_test = test_data['1_min_return'].values\n",
    "\n",
    "X_test, X_test.shape, y_test, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add More Functions and a Customized Backtest Fitness Function for GPlearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T11:01:13.774861Z",
     "start_time": "2022-08-23T11:01:13.456998Z"
    },
    "code_folding": [
     91,
     104,
     119,
     134,
     147,
     162,
     175,
     190,
     193,
     209,
     219,
     229,
     241,
     254,
     275,
     288,
     301,
     314,
     328,
     341,
     354,
     368,
     381,
     392,
     403,
     414,
     417,
     421,
     424,
     427,
     433
    ]
   },
   "outputs": [],
   "source": [
    "init_function = ['add', 'sub', 'mul', 'div','sqrt', 'log','inv','sin','max','min']\n",
    "def _ts_beta(x1, x2, n):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        try:\n",
    "            if n[0] == n[1] and n[1] == n[2]:\n",
    "                u'''need：(list1,list2,number)  return：number\n",
    "                前 n 期样本 A 对 B 做回归所得回归系数'''\n",
    "                list1 = x1.flatten().tolist()\n",
    "                list2 = x2.flatten().tolist()\n",
    "                n = int(n[0])\n",
    "                list1 = np.array(list1[-n-1:]).reshape(-1, 1)\n",
    "                list2 = np.array(list2[-n-1:]).reshape(-1, 1)\n",
    "                linreg = LinearRegression()\n",
    "                model = linreg.fit(list1, list2)\n",
    "                res = linreg.coef_.tolist()[0]\n",
    "                res = np.array(res+[0]*(len(x1)-len(linreg.coef_))).flatten()\n",
    "                return res\n",
    "            else:\n",
    "                return np.zeros(x1.shape[0])\n",
    "        except:\n",
    "            return np.zeros(x1.shape[0])\n",
    "        \n",
    "def _ts_resid(x1, x2, n):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        try:\n",
    "            if n[0] == n[1] and n[1] == n[2]:\n",
    "                u'''need：(list1,list2,number)  return：number\n",
    "                前 n 期样本 A 对 B 做回归所得的残差'''\n",
    "                list1 = x1.flatten().tolist()\n",
    "                list2 = x2.flatten().tolist()\n",
    "                n = int(n[0])\n",
    "                list1 = np.array(list1[-n-1:]).reshape(-1, 1)\n",
    "                list2 = np.array(list2[-n-1:]).reshape(-1, 1)\n",
    "                linreg = LinearRegression()\n",
    "                model = linreg.fit(list1, list2)\n",
    "                res = list(linreg.intercept_)\n",
    "                res = np.array(res+[0]*(len(x1)-len([linreg.intercept_]))).flatten()\n",
    "                return res\n",
    "            else:\n",
    "                return np.zeros(x1.shape[0])\n",
    "        except:\n",
    "            return np.zeros(x1.shape[0])\n",
    "        \n",
    "def _corr(data1,data2,n):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        try:\n",
    "            if n[0] == n[1] and n[1] ==n[2]:\n",
    "                window  = n[0]\n",
    "                x1 = pd.Series(data1.flatten())\n",
    "                x2 = pd.Series(data2.flatten())\n",
    "                df = pd.concat([x1,x2],axis=1)\n",
    "                temp = pd.Series()\n",
    "                for i in range(len(df)):\n",
    "                    if i<=window-2:\n",
    "                        temp[str(i)] = np.nan\n",
    "                    else:\n",
    "                        df2 = df.iloc[i-window+1:i,:]\n",
    "                        temp[str(i)] = df2.corr('spearman').iloc[1,0]\n",
    "                return np.nan_to_num(temp)\n",
    "            else:\n",
    "                return np.zeros(data1.shape[0])\n",
    "        except:\n",
    "            return np.zeros(data1.shape[0])\n",
    "        \n",
    "def SEQUENCE(n):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        try:\n",
    "            if n[0] == n[1] and n[1] == n[2]:\n",
    "                a = n[0]\n",
    "                res = np.array(list(range(1, a+1)))\n",
    "                res = res.tolist()+[0]*(len(n)-len(res))\n",
    "                return np.array(res).flatten()\n",
    "            else:\n",
    "                return np.zeros(n.shape[0])\n",
    "        except:\n",
    "            return np.zeros(n.shape[0])\n",
    "\n",
    "def _ts_prod(x, n):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        try:\n",
    "            if n[0] == n[1] and n[1] == n[2]:\n",
    "                x = pd.Series(x.flatten())\n",
    "                n = n[0]\n",
    "                res = x.prod(min_count=n)\n",
    "                res = np.array([res]+[0]*(len(x)-1))\n",
    "                return res\n",
    "            else:\n",
    "                return np.zeros(x.shape[0]) \n",
    "        except:\n",
    "            return np.zeros(data1.shape[0]) \n",
    "        \n",
    "def _ts_cov(x,y,window):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        try:\n",
    "            if n[0] == n[1] and n1[1] == n[2]:\n",
    "                x = pd.Series(x.flatten())\n",
    "                y = pd.Series(y.flatten())\n",
    "                res = x.rolling(window).cov(y).fillna(0).values\n",
    "                return res\n",
    "            else:\n",
    "                return np.zeros(x.shape[0]) \n",
    "        except:\n",
    "            return np.zeros(x.shape[0])\n",
    "\n",
    "def _ts_lowday(x1, n1):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        try:\n",
    "            if n1[0] == n1[1] and n1[1] == n1[2]:\n",
    "                '''need：(list,number)  return：number\n",
    "                计算 A 前 n 期时间序列中最小值距离当前时点的间隔'''\n",
    "                n = int(n1[0])\n",
    "                x = x1.flatten().tolist()    \n",
    "                lowday = n-x[-n:].index(min(list(x)[-n:]))-1\n",
    "                return np.array([lowday]+[0]*(len(x)-1))\n",
    "            else:\n",
    "                return np.zeros(x1.shape[0]) \n",
    "        except:\n",
    "            return np.zeros(x1.shape[0]) \n",
    "        \n",
    "def _ts_highday(x1, n1):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        try:\n",
    "            if n1[0] == n1[1] and n1[1] == n1[2]:\n",
    "                u'''need：(list,number)  return：number\n",
    "                计算 A 前 n 期时间序列中最大值距离当前时点的间隔'''\n",
    "                n = int(n1[0])\n",
    "                x = x1.flatten().tolist()\n",
    "                highday = n-x[-n:].index(max(list(x)[-n:]))-1\n",
    "                return np.array([highday]+[0]*(len(x)-1))\n",
    "            else:\n",
    "                return np.zeros(x1.shape[0]) \n",
    "        except:\n",
    "            return np.zeros(x1.shape[0]) \n",
    "        \n",
    "def _ts_adv(x,d):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        try:\n",
    "            if d[0] == d[1] and d[1] == d[2]:\n",
    "                d = int(d[0])\n",
    "                reslist(map(lambda t: np.mean(x.flatten()[t:t+20]),range(len(x.flatten())-d+1)))\n",
    "                res = res[numpy.isneginf(res)] = 0\n",
    "                return np.array(res)\n",
    "            else:\n",
    "                return np.zeros(x.shape[0])\n",
    "        except:\n",
    "            return np.zeros(x.shape[0])\n",
    "            \n",
    "def _ts_wma(x1,d):\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            try:\n",
    "                if d[0] == d[1] and d[1] == d[2]:\n",
    "                    d = int(d[0])\n",
    "                    x1 = pd.Series(x1.flatten())\n",
    "                    weights = np.arange(1,d+1)\n",
    "                    wma = x1.rolling(d).apply(lambda prices: np.dot(prices, weights)/weights.sum(), raw=True)\n",
    "                    wma = wma.fillna(0).values\n",
    "                    return wma\n",
    "                else:\n",
    "                    return np.zeros(x1.shape[0])\n",
    "            except:\n",
    "                return np.zeros(x1.shape[0])\n",
    "\n",
    "def _ts_mean(X, d):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        try:\n",
    "            if d[0] == d[1] and d[1] == d[2]:\n",
    "                X = pd.Series(X.flatten())\n",
    "                res = X.rolling(window=d[0]).mean()\n",
    "                res = res.fillna(0).values\n",
    "                return res\n",
    "            else:\n",
    "                return np.zeros(X.shape[0])\n",
    "        except:\n",
    "            return np.zeros(X.shape[0])\n",
    "\n",
    "def _decay_linear(data1,n):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        try:\n",
    "            if n[0] == n[1] and n[1] == n[2]:\n",
    "                n = int(n[0])\n",
    "                w = np.arange(1,n+1)\n",
    "                w = w[::-1]\n",
    "                w = np.array(w)/np.sum(w)\n",
    "                res = list(map(lambda t: np.sum(np.multiply(np.array(data1.flatten()[t:t+n]),w)),range(len(data1.flatten())-n+1)))\n",
    "                return np.array(res).flatten()\n",
    "            else:\n",
    "                return np.zeros(data1.shape[0])\n",
    "        except:\n",
    "            return np.zeros(data1.shape[0])\n",
    "\n",
    "def _abs(x1):\n",
    "    return abs(x1.flatten())\n",
    "\n",
    "def _ts_abs(data1, n):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        try:\n",
    "            if n[0] == n[1] and n[1] == n[2]:\n",
    "                window = int(n[0])\n",
    "                x1 = data1.flatten()\n",
    "                temp1 = x1[-window:]\n",
    "                temp1 = np.abs(temp1)\n",
    "                temp2 = x1[:-window]\n",
    "                result = np.append(temp2,temp1)\n",
    "                return result\n",
    "            else:\n",
    "                return np.zeros(data1.shape[0])\n",
    "        except:\n",
    "            return np.zeros(data1.shape[0]) \n",
    "\n",
    "def _ts_scale(data1, n):\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            try:\n",
    "                if n[0] == n[1] and n[1] == n[2]:\n",
    "                    return (int(n[0])*x1 / np.nansum(np.abs(data1.flatten())))\n",
    "                else:\n",
    "                    return np.zeros(data1.shape[0])\n",
    "            except:\n",
    "                return np.zeros(data1.shape[0])\n",
    "            \n",
    "def _signedpower(data1, n):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        try:\n",
    "            if n[0] == n[1] and n[1] == n[2]:\n",
    "                return np.sign(data1.flatten()) * np.power(np.abs(data1.flatten()), int(n[0]))\n",
    "            else:\n",
    "                return np.zeros(data1.shape[0])\n",
    "        except:\n",
    "            return np.zeros(data1.shape[0]) \n",
    "\n",
    "def _ts_delta(data1,n):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        try:\n",
    "            if n[0] == n[1] and n[1] == n[2]:\n",
    "                a1 = data1-pd.Series(data1.flatten()).shift(periods=int(n[0]))\n",
    "                a1 = a1.fillna(0).values\n",
    "                return a1\n",
    "            else:\n",
    "                return np.zeros(data1.shape[0])\n",
    "        except:\n",
    "            return np.zeros(data1.shape[0]) \n",
    "\n",
    "def _ts_delay(data1,n):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        try:\n",
    "            if n[0] == n[1] and n[1] == n[2]:\n",
    "                a1 = pd.Series(data1.flatten())\n",
    "                a1 = a1.shift(periods=int(n[0]))\n",
    "                a1 = a1.fillna(0).values\n",
    "                return a1\n",
    "            else:\n",
    "                return np.zeros(data1.shape[0])\n",
    "        except:\n",
    "            return np.zeros(data1.shape[0]) \n",
    "\n",
    "def _ts_corr(data1,data2,n):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        try:\n",
    "            if n[0] == n[1] and n[1] ==n[2]:\n",
    "                window = int(n[0])\n",
    "                x1 = pd.Series(data1.flatten())\n",
    "                x2 = pd.Series(data2.flatten())\n",
    "                df = pd.concat([x1,x2],axis=1)\n",
    "                temp = pd.Series()\n",
    "                for i in range(len(df)):\n",
    "                    if i<=window-2:\n",
    "                        temp[str(i)] = np.nan\n",
    "                    else:\n",
    "                        df2 = df.iloc[i-window+1:i,:]\n",
    "                        temp[str(i)] = df2.corr('spearman').iloc[1,0]\n",
    "                return np.nan_to_num(temp)\n",
    "            else:\n",
    "                return np.zeros(data1.shape[0])\n",
    "        except:\n",
    "            return np.zeros(data1.shape[0]) \n",
    "\n",
    "def _ts_sum(data,n):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        try:\n",
    "            if n[0] == n[1] and n[1] ==n[2]:\n",
    "                window = int(n[0])\n",
    "                value = np.array(pd.Series(data.flatten()).rolling(window).sum().tolist())\n",
    "                value = np.nan_to_num(value)\n",
    "                return value\n",
    "            else:\n",
    "                return np.zeros(data.shape[0])\n",
    "        except:\n",
    "            return np.zeros(data.shape[0])\n",
    "        \n",
    "def _ts_sma(data,n):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):   \n",
    "        try:\n",
    "            if n[0] == n[1] and n[1] ==n[2]:\n",
    "                window = int(n[0])\n",
    "                value = np.array(pd.Series(data.flatten()).rolling(window).mean().tolist())\n",
    "                value = np.nan_to_num(value)\n",
    "                return value\n",
    "            else:\n",
    "                return np.zeros(data.shape[0])\n",
    "        except:\n",
    "            return np.zeros(data.shape[0])\n",
    "\n",
    "def _ts_stddev(data,n):   \n",
    "    with np.errstate(divide='ignore', invalid='ignore'): \n",
    "        try:\n",
    "            if n[0] == n[1] and n[1] ==n[2]:\n",
    "                window = int(n[0])\n",
    "                value = np.array(pd.Series(data.flatten()).rolling(window).std().tolist())\n",
    "                value = np.nan_to_num(value)\n",
    "                return value\n",
    "            else:\n",
    "                return np.zeros(data.shape[0])\n",
    "        except:\n",
    "            return np.zeros(data.shape[0])\n",
    "\n",
    "def _ts_rank(x1,n):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        try:\n",
    "            if n[0] == n[1] and n[1] ==n[2]:\n",
    "                n = int(n[0])\n",
    "                x2 = pd.Series(x1.flatten()[-n:])\n",
    "                res = x2.rank(pct=True).values\n",
    "                res = res.tolist()+[0]*(x1.shape[0] - res.shape[0])\n",
    "                return np.array(res)\n",
    "            else:\n",
    "                return np.zeros(x1.shape[0]) \n",
    "        except:\n",
    "            return np.zeros(x1.shape[0]) \n",
    "        \n",
    "def _ts_argmin(data,n):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        try:\n",
    "            if n[0] == n[1] and n[1] ==n[2]:\n",
    "                window = int(n[0])\n",
    "                value = pd.Series(data.flatten()).rolling(window).apply(np.argmin) + 1 \n",
    "                value = np.nan_to_num(value)\n",
    "                return value\n",
    "            else:\n",
    "                return np.zeros(data.shape[0])  \n",
    "        except:\n",
    "            return np.zeros(data.shape[0])  \n",
    "\n",
    "def _ts_argmax(data,n):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        try:\n",
    "            if n[0] == n[1] and n[1] ==n[2]:\n",
    "                window = int(n[0])\n",
    "                value = pd.Series(data.flatten()).rolling(window).apply(np.argmax) + 1 \n",
    "                value = np.nan_to_num(value)\n",
    "                return value\n",
    "            else:\n",
    "                return np.zeros(data.shape[0])\n",
    "        except:\n",
    "            return np.zeros(data.shape[0]) \n",
    "        \n",
    "def _ts_min(data,n):\n",
    "    import numpy as np\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        try:\n",
    "            if n[0] == n[1] and n[1] ==n[2]:\n",
    "                window = int(n[0])\n",
    "                value = np.array(pd.Series(data.flatten()).rolling(window).min().tolist())\n",
    "                value = np.nan_to_num(value)\n",
    "                return value\n",
    "            else:\n",
    "                return np.zeros(data.shape[0])\n",
    "        except:\n",
    "            return np.zeros(data.shape[0])\n",
    "\n",
    "def _ts_max(data,n):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        try:\n",
    "            if n[0] == n[1] and n[1] ==n[2]:\n",
    "                window = int(n[0])\n",
    "                value = np.array(pd.Series(data.flatten()).rolling(window).max().tolist())\n",
    "                value = np.nan_to_num(value)\n",
    "                return value\n",
    "            else:\n",
    "                return np.zeros(data.shape[0])\n",
    "        except:\n",
    "            return np.zeros(data.shape[0])\n",
    "@jit\n",
    "def _beta(x1, x2):\n",
    "    list1 = x1.flatten().tolist()\n",
    "    list2 = x2.flatten().tolist()\n",
    "    list1 = np.array(list1).reshape(-1, 1)\n",
    "    list2 = np.array(list2).reshape(-1, 1)\n",
    "    linreg = LinearRegression()\n",
    "    model = linreg.fit(list1, list2)\n",
    "    res = linreg.coef_.tolist()[0]\n",
    "    res = np.array(res+[0]*(len(x1)-len(linreg.coef_))).flatten()\n",
    "    return res\n",
    "\n",
    "def _resid(x1, x2):\n",
    "    list1 = x1.flatten().tolist()\n",
    "    list2 = x2.flatten().tolist()\n",
    "    list1 = np.array(list1).reshape(-1, 1)\n",
    "    list2 = np.array(list2).reshape(-1, 1)\n",
    "    linreg = LinearRegression()\n",
    "    model = linreg.fit(list1, list2)\n",
    "    res = linreg.coef_.tolist()[0]\n",
    "    res = np.array(res+[0]*(len(x1)-len(linreg.intercept_))).flatten()\n",
    "    return res \n",
    "\n",
    "def _beta(x1, x2):\n",
    "    list1 = x1.flatten().tolist()\n",
    "    list2 = x2.flatten().tolist()\n",
    "    list1 = np.array(list1).reshape(-1, 1)\n",
    "    list2 = np.array(list2).reshape(-1, 1)\n",
    "    linreg = LinearRegression()\n",
    "    model = linreg.fit(list1, list2)\n",
    "    res = linreg.coef_.tolist()[0]\n",
    "    res = np.array(res+[0]*(len(x1)-len(linreg.coef_))).flatten()\n",
    "    return res\n",
    "\n",
    "def _abs(x1):\n",
    "    return abs(x1.flatten())\n",
    "\n",
    "def _rank(x1):\n",
    "    x1 = pd.Series(x1.flatten())\n",
    "    return x1.rank(pct=True).values\n",
    "        \n",
    "def _cube(data):\n",
    "    return np.square(data.flatten())*data.flatten()\n",
    "\n",
    "def _square(data):\n",
    "    return np.square(data.flatten())\n",
    "\n",
    "def _ts_argmaxmin(data,n):\n",
    "    try:\n",
    "        return _ts_argmax(data,n) - _ts_argmin(data,n)\n",
    "    except:\n",
    "        return np.zeros(data.shape[0])\n",
    "\n",
    "def _my_metric_backtest(y, y_pred, w):\n",
    "    pred = pd.Series(y_pred.flatten()).fillna(0)\n",
    "    y = pd.Series(y.flatten()).fillna(0)\n",
    "    short_profit = 0\n",
    "    long_profit = 0\n",
    "    held_long = 0\n",
    "    held_short = 0\n",
    "    profit = []\n",
    "    profit_temp = 0\n",
    "    \n",
    "    for i in range(len(pred)):\n",
    "        current_pred = pred.iloc[i]\n",
    "        current_return = y.iloc[i]\n",
    "        #open long\n",
    "        if current_pred>=0.75 and held_long==0 and held_short==0:\n",
    "            held_long = 1\n",
    "            held_short = 0\n",
    "            long_profit += current_return\n",
    "                    \n",
    "        #hold long\n",
    "        elif current_pred>=0.75 and held_long==1 and held_short==0:\n",
    "            held_long = 1\n",
    "            held_short = 0\n",
    "            long_profit += current_return\n",
    "            \n",
    "        #open long and close short\n",
    "        elif current_pred>=0.75 and held_long==0 and held_short==1:\n",
    "            #close short and record profit\n",
    "            held_long = 1\n",
    "            held_short = 0\n",
    "            short_profit += (-current_return)\n",
    "            profit.append(short_profit)\n",
    "            #open long\n",
    "            long_profit += current_return\n",
    "                    \n",
    "        #open short\n",
    "        elif current_pred<=-0.75and held_long==0 and held_short==0:\n",
    "            held_long = 0\n",
    "            held_short = 1\n",
    "            short_profit += (-current_return)\n",
    "            \n",
    "        #keep short\n",
    "        elif current_pred<=-0.75 and held_long==0 and held_short==1:\n",
    "            held_long = 0\n",
    "            held_short = 1\n",
    "            short_profit += (-current_return)\n",
    "  \n",
    "        #close long and open short\n",
    "        elif current_pred <=-0.75 and held_long==1 and held_short==0:\n",
    "            #close long\n",
    "            held_long = 0\n",
    "            held_short = 1\n",
    "            long_profit += current_return\n",
    "            profit.append(long_profit)\n",
    "            #open short\n",
    "            short_profit += (-current_return)\n",
    "                    \n",
    "        #closeout long \n",
    "        elif current_pred<0.75 and current_pred>-0.75 and held_long==1 and held_short==0:\n",
    "            held_long = 0\n",
    "            held_short = 0\n",
    "            long_profit += current_return\n",
    "            profit.append(long_profit)      \n",
    "            \n",
    "        #closeout short    \n",
    "        elif current_pred<0.75 and current_pred>-0.75 and held_long==0 and held_short==1:\n",
    "            held_long = 0\n",
    "            held_short = 0\n",
    "            short_profit += (-current_return)\n",
    "            profit.append(short_profit)\n",
    "    try:        \n",
    "        total_return = profit[-1]\n",
    "    except:\n",
    "        total_return = 0\n",
    "        \n",
    "    result = total_return\n",
    "    \n",
    "    del pred\n",
    "    del y\n",
    "    del short_profit\n",
    "    del long_profit\n",
    "    del held_long\n",
    "    del held_short\n",
    "    del profit\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activate The Customized Fuctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T11:01:25.841928Z",
     "start_time": "2022-08-23T11:01:25.747119Z"
    }
   },
   "outputs": [],
   "source": [
    "ts_beta = make_function(function = _ts_beta, name='ts_beta', arity=3, wrap=False)\n",
    "beta = make_function(function = _beta, name='beta', arity=2, wrap=False)\n",
    "ts_resid = make_function(function = _ts_resid, name='ts_resid', arity=3, wrap=False)\n",
    "resid = make_function(function = _resid, name='resid', arity=2, wrap=False)\n",
    "corr = make_function(function = _corr, name='corr', arity=3, wrap=False) \n",
    "SEQUENCE = make_function(function=SEQUENCE, name='SEQUENCE', arity=1, wrap=False) \n",
    "ts_cov = make_function(function=_ts_cov, name='ts_cov', arity=3, wrap=False) \n",
    "ts_lowday = make_function(function=_ts_lowday, name='ts_lowday', arity=2, wrap=False) \n",
    "ts_highday = make_function(function=_ts_highday, name='ts_highday', arity=2, wrap=False) \n",
    "ts_adv = make_function(function=_ts_adv, name='ts_adv', arity=2, wrap=False)  \n",
    "ts_wma = make_function(function=_ts_wma, name='ts_wma', arity=2, wrap=False)       \n",
    "ts_mean = make_function(function=_ts_mean, name='ts_mean', arity=2, wrap=False) \n",
    "decay_linear = make_function(function=_decay_linear, name='decay_linear', arity=2, wrap=False) \n",
    "_abs = make_function(function=_abs, name='_abs', arity=1, wrap=False) \n",
    "ts_abs = make_function(function=_ts_abs, name='ts_abs', arity=2, wrap=False) \n",
    "rank = make_function(function=_rank, name='rank', arity=1, wrap=False) \n",
    "ts_scale = make_function(function=_ts_scale, name='ts_scale', arity=2, wrap=False) \n",
    "ts_delta = make_function(function=_ts_delta, name='ts_delta', arity=2, wrap=False) \n",
    "ts_delay = make_function(function=_ts_delay, name='ts_delay', arity=2, wrap=False)  \n",
    "ts_sma = make_function(function=_ts_sma, name='ts_sma', arity=2, wrap=False)     \n",
    "ts_std = make_function(function=_ts_stddev, name='ts_std', arity=2, wrap=False)     \n",
    "ts_rank = make_function(function=_ts_rank, name='ts_rank', arity=2, wrap=False)\n",
    "ts_stddev = make_function(function=_ts_stddev, name='ts_stddev', arity=2, wrap=False)\n",
    "ts_sum = make_function(function=_ts_sum, name='ts_sum', arity=2, wrap=False)\n",
    "ts_corr = make_function(function=_ts_corr, name='ts_corr', arity=3, wrap=False)\n",
    "ts_min = make_function(function=_ts_min, name='ts_min', arity=2, wrap=False)\n",
    "cube = make_function(function=_cube, name='cube', arity=1, wrap=False)\n",
    "square = make_function(function=_square, name='square', arity=1, wrap=False)\n",
    "ts_argmaxmin = make_function(function=_ts_argmaxmin, name='ts_argmaxmin', arity=2, wrap=False)\n",
    "ts_argmax = make_function(function=_ts_argmax, name='ts_argmax', arity=2)\n",
    "ts_argmin = make_function(function=_ts_argmin, name='ts_argmin', arity=2, wrap=False)\n",
    "ts_min = make_function(function=_ts_min, name='ts_min', arity=2, wrap=False)\n",
    "ts_max = make_function(function=_ts_max, name='ts_max', arity=2, wrap=False)\n",
    "#decay_linear,ts_corr(replaced by corr),\n",
    "user_function = [SEQUENCE, ts_cov, ts_lowday, ts_highday, ts_adv, ts_wma, ts_mean, _abs, rank, ts_scale, ts_delta, ts_delay, \n",
    "                 ts_sma, ts_std, ts_rank, ts_sum, corr, ts_min, cube, square, ts_argmaxmin, ts_argmax, ts_argmin, ts_min, ts_max, ts_beta,\n",
    "                beta, ts_resid, resid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activate The Customized Fitness Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T11:01:30.155928Z",
     "start_time": "2022-08-23T11:01:30.150610Z"
    }
   },
   "outputs": [],
   "source": [
    "my_metric = make_fitness(function=_my_metric_backtest, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T11:07:54.487927Z",
     "start_time": "2022-08-23T11:06:14.369331Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    |   Population Average    |             Best Individual              |\n",
      "---- ------------------------- ------------------------------------------ ----------\n",
      " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "/var/folders/w5/_3s473zj6jdcfc2321zm2cwh0000gn/T/ipykernel_24523/2880920555.py:52: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/var/folders/w5/_3s473zj6jdcfc2321zm2cwh0000gn/T/ipykernel_24523/2880920555.py:52: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/var/folders/w5/_3s473zj6jdcfc2321zm2cwh0000gn/T/ipykernel_24523/2880920555.py:52: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/var/folders/w5/_3s473zj6jdcfc2321zm2cwh0000gn/T/ipykernel_24523/2880920555.py:52: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/var/folders/w5/_3s473zj6jdcfc2321zm2cwh0000gn/T/ipykernel_24523/2880920555.py:52: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/var/folders/w5/_3s473zj6jdcfc2321zm2cwh0000gn/T/ipykernel_24523/2880920555.py:52: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/var/folders/w5/_3s473zj6jdcfc2321zm2cwh0000gn/T/ipykernel_24523/2880920555.py:52: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/var/folders/w5/_3s473zj6jdcfc2321zm2cwh0000gn/T/ipykernel_24523/2880920555.py:52: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/var/folders/w5/_3s473zj6jdcfc2321zm2cwh0000gn/T/ipykernel_24523/2880920555.py:52: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/var/folders/w5/_3s473zj6jdcfc2321zm2cwh0000gn/T/ipykernel_24523/2880920555.py:52: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/var/folders/w5/_3s473zj6jdcfc2321zm2cwh0000gn/T/ipykernel_24523/2880920555.py:52: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/var/folders/w5/_3s473zj6jdcfc2321zm2cwh0000gn/T/ipykernel_24523/2880920555.py:52: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/var/folders/w5/_3s473zj6jdcfc2321zm2cwh0000gn/T/ipykernel_24523/2880920555.py:52: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/var/folders/w5/_3s473zj6jdcfc2321zm2cwh0000gn/T/ipykernel_24523/2880920555.py:52: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/var/folders/w5/_3s473zj6jdcfc2321zm2cwh0000gn/T/ipykernel_24523/2880920555.py:52: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/var/folders/w5/_3s473zj6jdcfc2321zm2cwh0000gn/T/ipykernel_24523/2880920555.py:52: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/var/folders/w5/_3s473zj6jdcfc2321zm2cwh0000gn/T/ipykernel_24523/2880920555.py:52: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/var/folders/w5/_3s473zj6jdcfc2321zm2cwh0000gn/T/ipykernel_24523/2880920555.py:52: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/var/folders/w5/_3s473zj6jdcfc2321zm2cwh0000gn/T/ipykernel_24523/2880920555.py:52: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/var/folders/w5/_3s473zj6jdcfc2321zm2cwh0000gn/T/ipykernel_24523/2880920555.py:52: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/var/folders/w5/_3s473zj6jdcfc2321zm2cwh0000gn/T/ipykernel_24523/2880920555.py:52: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/var/folders/w5/_3s473zj6jdcfc2321zm2cwh0000gn/T/ipykernel_24523/2880920555.py:52: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/var/folders/w5/_3s473zj6jdcfc2321zm2cwh0000gn/T/ipykernel_24523/2880920555.py:52: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/var/folders/w5/_3s473zj6jdcfc2321zm2cwh0000gn/T/ipykernel_24523/2880920555.py:52: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/var/folders/w5/_3s473zj6jdcfc2321zm2cwh0000gn/T/ipykernel_24523/2880920555.py:52: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/var/folders/w5/_3s473zj6jdcfc2321zm2cwh0000gn/T/ipykernel_24523/2880920555.py:52: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/var/folders/w5/_3s473zj6jdcfc2321zm2cwh0000gn/T/ipykernel_24523/2880920555.py:52: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/var/folders/w5/_3s473zj6jdcfc2321zm2cwh0000gn/T/ipykernel_24523/2880920555.py:52: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/var/folders/w5/_3s473zj6jdcfc2321zm2cwh0000gn/T/ipykernel_24523/2880920555.py:52: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/var/folders/w5/_3s473zj6jdcfc2321zm2cwh0000gn/T/ipykernel_24523/2880920555.py:52: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/var/folders/w5/_3s473zj6jdcfc2321zm2cwh0000gn/T/ipykernel_24523/2880920555.py:52: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/var/folders/w5/_3s473zj6jdcfc2321zm2cwh0000gn/T/ipykernel_24523/2880920555.py:52: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/var/folders/w5/_3s473zj6jdcfc2321zm2cwh0000gn/T/ipykernel_24523/2880920555.py:52: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/var/folders/w5/_3s473zj6jdcfc2321zm2cwh0000gn/T/ipykernel_24523/2880920555.py:52: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/var/folders/w5/_3s473zj6jdcfc2321zm2cwh0000gn/T/ipykernel_24523/2880920555.py:52: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/var/folders/w5/_3s473zj6jdcfc2321zm2cwh0000gn/T/ipykernel_24523/2880920555.py:52: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/var/folders/w5/_3s473zj6jdcfc2321zm2cwh0000gn/T/ipykernel_24523/2880920555.py:52: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/var/folders/w5/_3s473zj6jdcfc2321zm2cwh0000gn/T/ipykernel_24523/2880920555.py:52: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/var/folders/w5/_3s473zj6jdcfc2321zm2cwh0000gn/T/ipykernel_24523/2880920555.py:52: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/var/folders/w5/_3s473zj6jdcfc2321zm2cwh0000gn/T/ipykernel_24523/2880920555.py:52: FutureWarning: The default dtype for empty Series will be 'object' instead of 'fl"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>limit_output extension: Maximum message size of 10000 exceeded with 16424 characters</b>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TerminatedWorkerError",
     "evalue": "A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {SIGKILL(-9)}",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTerminatedWorkerError\u001B[0m                     Traceback (most recent call last)",
      "Input \u001B[0;32mIn [26]\u001B[0m, in \u001B[0;36m<cell line: 24>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     22\u001B[0m X_train \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mnan_to_num(X_train)\n\u001B[1;32m     23\u001B[0m y_train \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mnan_to_num(y_train)\n\u001B[0;32m---> 24\u001B[0m \u001B[43mest_gp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.conda/envs/GPlearn_finiance_stock_futures_extension/lib/python3.8/site-packages/gplearn/genetic.py:476\u001B[0m, in \u001B[0;36mBaseSymbolic.fit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m    472\u001B[0m n_jobs, n_programs, starts \u001B[38;5;241m=\u001B[39m _partition_estimators(\n\u001B[1;32m    473\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpopulation_size, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_jobs)\n\u001B[1;32m    474\u001B[0m seeds \u001B[38;5;241m=\u001B[39m random_state\u001B[38;5;241m.\u001B[39mrandint(MAX_INT, size\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpopulation_size)\n\u001B[0;32m--> 476\u001B[0m population \u001B[38;5;241m=\u001B[39m \u001B[43mParallel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    477\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m>\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    478\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_parallel_evolve\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_programs\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    479\u001B[0m \u001B[43m                              \u001B[49m\u001B[43mparents\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    480\u001B[0m \u001B[43m                              \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    481\u001B[0m \u001B[43m                              \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    482\u001B[0m \u001B[43m                              \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    483\u001B[0m \u001B[43m                              \u001B[49m\u001B[43mseeds\u001B[49m\u001B[43m[\u001B[49m\u001B[43mstarts\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m:\u001B[49m\u001B[43mstarts\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    484\u001B[0m \u001B[43m                              \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    485\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mrange\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    487\u001B[0m \u001B[38;5;66;03m# Reduce, maintaining order across different n_jobs\u001B[39;00m\n\u001B[1;32m    488\u001B[0m population \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(itertools\u001B[38;5;241m.\u001B[39mchain\u001B[38;5;241m.\u001B[39mfrom_iterable(population))\n",
      "File \u001B[0;32m~/.conda/envs/GPlearn_finiance_stock_futures_extension/lib/python3.8/site-packages/joblib/parallel.py:1056\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1053\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m   1055\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mretrieval_context():\n\u001B[0;32m-> 1056\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mretrieve\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1057\u001B[0m \u001B[38;5;66;03m# Make sure that we get a last message telling us we are done\u001B[39;00m\n\u001B[1;32m   1058\u001B[0m elapsed_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_start_time\n",
      "File \u001B[0;32m~/.conda/envs/GPlearn_finiance_stock_futures_extension/lib/python3.8/site-packages/joblib/parallel.py:935\u001B[0m, in \u001B[0;36mParallel.retrieve\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    933\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    934\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msupports_timeout\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m--> 935\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output\u001B[38;5;241m.\u001B[39mextend(\u001B[43mjob\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    936\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    937\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output\u001B[38;5;241m.\u001B[39mextend(job\u001B[38;5;241m.\u001B[39mget())\n",
      "File \u001B[0;32m~/.conda/envs/GPlearn_finiance_stock_futures_extension/lib/python3.8/site-packages/joblib/_parallel_backends.py:542\u001B[0m, in \u001B[0;36mLokyBackend.wrap_future_result\u001B[0;34m(future, timeout)\u001B[0m\n\u001B[1;32m    539\u001B[0m \u001B[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001B[39;00m\n\u001B[1;32m    540\u001B[0m \u001B[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001B[39;00m\n\u001B[1;32m    541\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 542\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfuture\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    543\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m CfTimeoutError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    544\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTimeoutError\u001B[39;00m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "File \u001B[0;32m~/.conda/envs/GPlearn_finiance_stock_futures_extension/lib/python3.8/concurrent/futures/_base.py:444\u001B[0m, in \u001B[0;36mFuture.result\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    442\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n\u001B[1;32m    443\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[0;32m--> 444\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__get_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    445\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    446\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTimeoutError\u001B[39;00m()\n",
      "File \u001B[0;32m~/.conda/envs/GPlearn_finiance_stock_futures_extension/lib/python3.8/concurrent/futures/_base.py:389\u001B[0m, in \u001B[0;36mFuture.__get_result\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    387\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception:\n\u001B[1;32m    388\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 389\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception\n\u001B[1;32m    390\u001B[0m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    391\u001B[0m         \u001B[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001B[39;00m\n\u001B[1;32m    392\u001B[0m         \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[0;31mTerminatedWorkerError\u001B[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n\nThe exit codes of the workers are {SIGKILL(-9)}"
     ]
    }
   ],
   "source": [
    "function_set = init_function + user_function\n",
    "population_size = 5000\n",
    "generations = 100\n",
    "random_state= 5\n",
    "est_gp = SymbolicTransformer(\n",
    "                            feature_names=fields, \n",
    "                            function_set=function_set,\n",
    "                            generations=generations,\n",
    "                            metric=my_metric,\n",
    "                            population_size=population_size,\n",
    "                            tournament_size=30, \n",
    "                            random_state=random_state,\n",
    "                            verbose=2, hall_of_fame=100,\n",
    "                            parsimony_coefficient=0.0001,\n",
    "                            p_crossover = 0.4,\n",
    "                            p_subtree_mutation = 0.01,\n",
    "                            p_hoist_mutation = 0,\n",
    "                            p_point_mutation = 0.01,\n",
    "                            p_point_replace = 0.4,\n",
    "                            n_jobs = 8)\n",
    "     \n",
    "X_train = np.nan_to_num(X_train)\n",
    "y_train = np.nan_to_num(y_train)\n",
    "est_gp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resulting Alpha Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T04:11:59.659567Z",
     "start_time": "2021-09-26T04:11:59.644568Z"
    }
   },
   "outputs": [],
   "source": [
    "best_programs = est_gp._best_programs\n",
    "best_programs_dict = {}\n",
    "\n",
    "for p in best_programs:\n",
    "    factor_name = 'alpha_' + str(best_programs.index(p) + 1)\n",
    "    best_programs_dict[factor_name] = {'fitness':p.fitness_, 'expression':str(p), 'depth':p.depth_, 'length':p.length_}\n",
    "     \n",
    "best_programs_dict = pd.DataFrame(best_programs_dict).T\n",
    "best_programs_dict = best_programs_dict.sort_values(by='fitness')\n",
    "best_programs_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T04:12:06.269981Z",
     "start_time": "2021-09-26T04:12:06.012909Z"
    }
   },
   "outputs": [],
   "source": [
    "filename = 'gplearn_PTA_1min_factors.pkl'\n",
    "with open(filename, 'wb') as f:\n",
    "     cloudpickle.dump(est_gp, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read The Model File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T04:12:07.035997Z",
     "start_time": "2021-09-26T04:12:06.983811Z"
    }
   },
   "outputs": [],
   "source": [
    "filename = 'gplearn_PTA_1min_factors.pkl'\n",
    "with open(filename, 'rb') as f:\n",
    "    est_gp = cloudpickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T04:12:07.530387Z",
     "start_time": "2021-09-26T04:12:07.519388Z"
    }
   },
   "outputs": [],
   "source": [
    "best_programs = est_gp._best_programs\n",
    "best_programs_dict = {}\n",
    "\n",
    "for p in best_programs:\n",
    "    factor_name = 'alpha_' + str(best_programs.index(p) + 1)\n",
    "    best_programs_dict[factor_name] = {'fitness':p.fitness_, 'expression':str(p), 'depth':p.depth_, 'length':p.length_}\n",
    "     \n",
    "best_programs_dict = pd.DataFrame(best_programs_dict).T\n",
    "best_programs_dict = best_programs_dict.sort_values(by='fitness')\n",
    "best_programs_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize The Alpha Factor Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T04:12:11.459831Z",
     "start_time": "2021-09-26T04:12:11.230868Z"
    }
   },
   "outputs": [],
   "source": [
    "def alpha_factor_graph(num):\n",
    "    # 打印指定num的表达式图\n",
    "\n",
    "    factor = best_programs[num-1]\n",
    "    print(factor)\n",
    "    print('fitness: {0}, depth: {1}, length: {2}'.format(factor.fitness_, factor.depth_, factor.length_))\n",
    "\n",
    "    dot_data = factor.export_graphviz()\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    graph.render('images/alpha_factor_graph', format='png', cleanup=True)\n",
    "    \n",
    "    return graph\n",
    "\n",
    "graph1 = alpha_factor_graph(1)\n",
    "graph1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T04:12:11.645879Z",
     "start_time": "2021-09-26T04:12:11.642879Z"
    }
   },
   "outputs": [],
   "source": [
    "factor = best_programs[0]\n",
    "print(factor)\n",
    "print('fitness: {0}, depth: {1}, length: {2}'.format(factor.fitness_, factor.depth_, factor.length_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alpha Factor Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 因子回测函数 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T04:12:14.143970Z",
     "start_time": "2021-09-26T04:12:14.128971Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def _factor_backtest(factor_perd, market_price):\n",
    "    pred = pd.Series(factor_perd.flatten()).fillna(0)\n",
    "    evaluation = []\n",
    "    slippage = 4\n",
    "    shares = 25\n",
    "    comission = 0.00025\n",
    "     \n",
    "    backtest_data = market_price\n",
    "    trades = pred\n",
    "\n",
    "    short_open = 0\n",
    "    long_open = 0\n",
    "    held_long = 0\n",
    "    held_short = 0\n",
    "    profit = []\n",
    "    profit_temp = 0\n",
    "    initial_assets = shares*max(backtest_data.open.values)\n",
    "    initial_cash = shares*max(backtest_data.open.values)\n",
    "    net_worth = [initial_cash]\n",
    "    \n",
    "    for i in range(len(trades)):\n",
    "        current_pred = trades.iloc[i]\n",
    "        current_close = backtest_data.iloc[i].open.astype('float')\n",
    "        #open long\n",
    "        if current_pred>=0.75 and held_long==0 and held_short==0:\n",
    "            held_long = 1\n",
    "            held_short = 0\n",
    "            long_open = current_close+slippage\n",
    "            short_open = 0\n",
    "            #print('open long')\n",
    "                    \n",
    "        #hold long\n",
    "        elif current_pred>=0.75 and held_long==1 and held_short==0:\n",
    "            #print('hold long')\n",
    "            pass\n",
    "                \n",
    "            #open long and close short\n",
    "        elif current_pred>=0.75 and held_long==0 and held_short==1:\n",
    "            held_long = 1\n",
    "            #close short and calculate profit\n",
    "            held_short = 0\n",
    "            profit_temp = (short_open-(current_close+slippage))*shares*(1-comission)\n",
    "            initial_cash += profit_temp\n",
    "            profit.append(profit_temp)\n",
    "            net_worth.append(initial_cash)\n",
    "            #open long\n",
    "            short_open = 0\n",
    "            long_open = current_close+slippage\n",
    "            #print('open long and close short')\n",
    "                    \n",
    "        #open short\n",
    "        elif current_pred<=-0.75and held_long==0 and held_short==0:\n",
    "            held_long = 0\n",
    "            held_short = 1\n",
    "            long_open = long_open\n",
    "            short_open = current_close+slippage\n",
    "            profit = profit\n",
    "            #print('open short')\n",
    "            \n",
    "        #keep short\n",
    "        elif current_pred<=-0.75 and held_long==0 and held_short==1:\n",
    "            #print('keep short')\n",
    "            pass\n",
    "                \n",
    "        #close long and open short\n",
    "        elif current_pred <=-0.75 and held_long==1 and held_short==0:\n",
    "            #close long\n",
    "            held_long = 0\n",
    "            held_short = 1\n",
    "            profit_temp = ((current_close-slippage)-long_open)*shares*(1-comission)\n",
    "            initial_cash += profit_temp\n",
    "            profit.append(profit_temp)\n",
    "            net_worth.append(initial_cash)\n",
    "            #open short\n",
    "            long_open = 0\n",
    "            short_open = current_close-slippage\n",
    "            profit = profit\n",
    "            #print('close long and open short')\n",
    "                    \n",
    "        #closeout long\n",
    "        elif current_pred<0.75 and current_pred>-0.75 and held_long==1 and held_short==0:\n",
    "            held_long = 0\n",
    "            held_short = 0\n",
    "            profit_temp = ((current_close-slippage)-long_open)*shares*(1-comission)\n",
    "            initial_cash += profit_temp\n",
    "            profit.append(profit_temp)\n",
    "            net_worth.append(initial_cash)\n",
    "            short_open = 0\n",
    "            long_open = 0\n",
    "            #print('closeout long')        \n",
    "            \n",
    "        #closeout short    \n",
    "        elif current_pred<0.75 and current_pred>-0.75 and held_long==0 and held_short==1:\n",
    "            held_long = 0\n",
    "            held_short = 0\n",
    "            profit_temp = (short_open-(current_close+slippage))*shares*(1-comission)\n",
    "            initial_cash += profit_temp\n",
    "            profit.append(profit_temp)\n",
    "            net_worth.append(initial_cash)\n",
    "            short_open = 0\n",
    "            long_open = 0\n",
    "            #print('closeout short')\n",
    "            \n",
    "    total_return = (initial_cash-initial_assets)/initial_assets\n",
    "    print('总收益率', total_return)\n",
    "    shaprpe_df = pd.Series(profit)\n",
    "    sharpe_temp = (shaprpe_df - shaprpe_df.shift(1))/shaprpe_df.shift(1)\n",
    "    sharpe = sharpe_temp.mean()/sharpe_temp.std()*np.sqrt(len(profit))\n",
    "          \n",
    "    a = np.maximum.accumulate(net_worth)\n",
    "    l = np.argmax((np.maximum.accumulate(net_worth) - net_worth)/np.maximum.accumulate(net_worth))\n",
    "    k = np.argmax(net_worth[:l])\n",
    "    max_draw = (net_worth[k] - net_worth[l])/(net_worth[l]) \n",
    "    print('最大回撤', max_draw)        \n",
    "        \n",
    "    win_count = 0\n",
    "    loss_count = 0\n",
    "    initial_profit = 0\n",
    "    for i in range(len(net_worth)):\n",
    "        current_profit = net_worth[i]\n",
    "        if i==0:\n",
    "            if current_profit > initial_assets:\n",
    "                win_count += 1\n",
    "            else:\n",
    "                loss_count += 1\n",
    "        else:\n",
    "            last_profit = net_worth[i-1]\n",
    "            if current_profit > last_profit:\n",
    "                win_count += 1\n",
    "            else:\n",
    "                loss_count += 1\n",
    "    win_rate = win_count/len(net_worth)\n",
    "    print('胜率', win_rate)\n",
    "    \n",
    "    total_gain = 0\n",
    "    total_loss = 0\n",
    "    for i in range(len(profit)):\n",
    "        if profit[i] >0:\n",
    "            total_gain += profit[i]\n",
    "        else:\n",
    "            total_loss += profit[i]\n",
    "    gain_loss_ratio = (total_gain/win_count)/(abs(total_loss)/loss_count)\n",
    "    print('盈亏比', gain_loss_ratio)\n",
    "    \n",
    "    result = total_return*np.nan_to_num(sharpe,nan=1)*win_rate*gain_loss_ratio*(1-max_draw)\n",
    "    \n",
    "    x = np.array(net_worth).reshape(len(net_worth),)\n",
    "    y = np.arange(len(net_worth))\n",
    "    \n",
    "    plt.rcParams['font.sans-serif'] = ['KaiTi'] # 指定默认字体\n",
    "    plt.rcParams['axes.unicode_minus'] = False # 解决保存图像是负号'-'显示为方块的问题\n",
    "    fig = plt.figure(figsize=(16,9))\n",
    "    plt.plot(y, x)\n",
    "    plt.title('因子资金曲线',fontsize=20)\n",
    "    plt.xlabel('交易次数',fontsize=20)\n",
    "    plt.ylabel('账户净值',fontsize=20)\n",
    "    plt.show()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Alpha Factor Backtest Results (In-Sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T04:12:15.887437Z",
     "start_time": "2021-09-26T04:12:15.082423Z"
    }
   },
   "outputs": [],
   "source": [
    "factors_pred = est_gp.transform(X_train)\n",
    "factors_pred.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T04:12:16.026423Z",
     "start_time": "2021-09-26T04:12:15.981422Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_data = pd.DataFrame(factors_pred).T.T\n",
    "pred_data, pred_data.iloc[:,[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alpha Factor Backtest Results (In-Sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T04:13:20.214386Z",
     "start_time": "2021-09-26T04:12:16.722885Z"
    }
   },
   "outputs": [],
   "source": [
    "#Total Rate of Return: 总收益率\n",
    "#Max drawdown: 最大回撤\n",
    "#Wining Rate: 胜率\n",
    "#Win-loss ratio:盈亏比\n",
    "#Graph Title: Factor Backtest Account Networth cruve\n",
    "#Graph X Axis: Number of Trades\n",
    "#Graph y Axis: Account Networth\n",
    "_factor_backtest(pred_data.iloc[:,[0]].values, train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Alpha Factor Backtest Results (Out-of-Sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T04:13:20.477401Z",
     "start_time": "2021-09-26T04:13:20.339386Z"
    }
   },
   "outputs": [],
   "source": [
    "factors_pred_1 = est_gp.transform(X_test)\n",
    "factors_pred_1.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T04:13:20.647386Z",
     "start_time": "2021-09-26T04:13:20.618386Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_data_1 = pd.DataFrame(factors_pred_1).T.T\n",
    "pred_data_1, pred_data_1.iloc[:,[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alpha Factor Backtest Results (Out-of-Sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T04:13:30.897424Z",
     "start_time": "2021-09-26T04:13:20.786386Z"
    }
   },
   "outputs": [],
   "source": [
    "#Total Rate of Return: 总收益率\n",
    "#Max drawdown: 最大回撤\n",
    "#Wining Rate: 胜率\n",
    "#Win-loss ratio:盈亏比\n",
    "#Graph Title: Factor Backtest Account Networth cruve\n",
    "#Graph X Axis: Number of Trades\n",
    "#Graph y Axis: Account Networth\n",
    "_factor_backtest(pred_data_1.iloc[:,[0]].values, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "MarkDown菜单",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}