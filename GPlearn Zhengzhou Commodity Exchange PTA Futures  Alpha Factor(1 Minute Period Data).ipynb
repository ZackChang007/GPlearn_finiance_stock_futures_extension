{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPlearn 1 Minute  Period Data Alpha Factor Generating\n",
    "## What is Alpha Factor?\n",
    "Alpha (α) is a term used in investing to describe an investment strategy's ability to beat the market, or its \"edge.\" Alpha is thus also often referred to as “excess return” or “abnormal rate of return,” which refers to the idea that markets are efficient, and so there is no way to systematically earn returns that exceed the broad market as a whole. Alpha is often used in conjunction with beta (the Greek letter β), which measures the broad market's overall volatility or risk, known as systematic market risk.  \n",
    "\n",
    "Alpha is used in finance as a measure of performance, indicating when a strategy, trader, or portfolio manager has managed to beat the market return over some period. Alpha, often considered the active return on an investment, gauges the performance of an investment against a market index or benchmark that is considered to represent the market’s movement as a whole.  \n",
    "\n",
    "The excess return of an investment relative to the return of a benchmark index is the investment’s alpha. Alpha may be positive or negative and is the result of active investing. Beta, on the other hand, can be earned through passive index investing.(Retrived from https://www.investopedia.com/terms/a/alpha.asp)  \n",
    "\n",
    "Alpha Factor is a mathmatical expression that tries to identify the strategy that can provide information on the future trend of the market. Alpha factor examples can be found on https://www.spglobal.com/marketintelligence/en/solutions/alpha-factor-library.  \n",
    "## What is GPlearn and symbolic transformer?\n",
    "gplearn implements Genetic Programming in Python, with a scikit-learn inspired and compatible API.\n",
    "\n",
    "While Genetic Programming (GP) can be used to perform a very wide variety of tasks, gplearn is purposefully constrained to solving symbolic regression problems. This is motivated by the scikit-learn ethos, of having powerful estimators that are straight-forward to implement.Genetic programming is capable of taking a series of totally random programs, untrained and unaware of any given target function you might have had in mind, and making them breed, mutate and evolve their way towards the truth.\n",
    "\n",
    "Think of genetic programming as a stochastic optimization process. Every time an initial population is conceived, and with every selection and evolution step in the process, random individuals from the current generation are selected to undergo random changes in order to enter the next. You can control this randomness by using the random_state parameter of the estimator.  \n",
    "\n",
    "A symbolic transformer is a supervised transformer that begins by building a population of naive random formulas to represent a relationship. The formulas are represented as tree-like structures with mathematical functions being recursively applied to variables and constants. Each successive generation of programs is then evolved from the one that came before it by selecting the fittest individuals from the population to undergo genetic operations such as crossover, mutation or reproduction. The final population is searched for the fittest individuals with the least correlation to one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-07T02:24:59.596065Z",
     "start_time": "2022-09-07T02:24:59.577284Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import graphviz\n",
    "\n",
    "from scipy.stats import rankdata\n",
    "import scipy.stats as stats\n",
    "\n",
    "from gplearn import genetic\n",
    "from gplearn.functions import make_function\n",
    "from gplearn.genetic import SymbolicTransformer, SymbolicRegressor\n",
    "from gplearn.fitness import make_fitness\n",
    "\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.model_selection import train_test_split\n",
    "import baostock as bs\n",
    "from ta.volume import VolumeWeightedAveragePrice\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats.mstats import zscore\n",
    "import talib\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "import datetime\n",
    "from numba import jit\n",
    "import scipy.stats as stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import math\n",
    "import cloudpickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-07T02:25:01.750533Z",
     "start_time": "2022-09-07T02:25:01.708043Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8000 entries, 0 to 7999\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   date    8000 non-null   datetime64[ns]\n",
      " 1   open    8000 non-null   float64       \n",
      " 2   high    8000 non-null   float64       \n",
      " 3   low     8000 non-null   float64       \n",
      " 4   close   8000 non-null   float64       \n",
      " 5   volume  8000 non-null   float64       \n",
      " 6   money   8000 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(6)\n",
      "memory usage: 437.6 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                 date    open    high     low   close  volume       money\n",
       " 0 2022-06-21 13:55:00  6928.0  6934.0  6926.0  6932.0  2053.0  71143293.0\n",
       " 1 2022-06-21 13:56:00  6932.0  6934.0  6926.0  6926.0   806.0  27922527.0\n",
       " 2 2022-06-21 13:57:00  6926.0  6932.0  6926.0  6930.0   678.0  23490440.0,\n",
       " None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv('dataset/PTA1分钟历史数据.csv', parse_dates=['date'])\n",
    "\n",
    "data_df.head(3), data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-07T02:25:05.801540Z",
     "start_time": "2022-09-07T02:25:05.763151Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8000 entries, 0 to 7999\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   date    8000 non-null   datetime64[ns]\n",
      " 1   open    8000 non-null   float64       \n",
      " 2   high    8000 non-null   float64       \n",
      " 3   low     8000 non-null   float64       \n",
      " 4   close   8000 non-null   float64       \n",
      " 5   volume  8000 non-null   float64       \n",
      " 6   money   8000 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(6)\n",
      "memory usage: 437.6 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                    date    open    high     low   close   volume        money\n",
       " 7997 2022-07-22 14:57:00  5620.0  5640.0  5620.0  5634.0  10553.0  297137303.0\n",
       " 7998 2022-07-22 14:58:00  5634.0  5640.0  5630.0  5640.0   8149.0  229665983.0\n",
       " 7999 2022-07-22 14:59:00  5640.0  5658.0  5640.0  5648.0  13682.0  386425287.0,\n",
       "                  date    open    high     low   close  volume       money\n",
       " 0 2022-06-21 13:55:00  6928.0  6934.0  6926.0  6932.0  2053.0  71143293.0\n",
       " 1 2022-06-21 13:56:00  6932.0  6934.0  6926.0  6926.0   806.0  27922527.0\n",
       " 2 2022-06-21 13:57:00  6926.0  6932.0  6926.0  6930.0   678.0  23490440.0,\n",
       " date      False\n",
       " open      False\n",
       " high      False\n",
       " low       False\n",
       " close     False\n",
       " volume    False\n",
       " money     False\n",
       " dtype: bool,\n",
       " None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields = ['open','close','high','low','volume','money']\n",
    "length = []\n",
    "\n",
    "df = data_df.copy()\n",
    "df.high = df.high.values.astype('float64')\n",
    "df.low = df.low.values.astype('float64')\n",
    "df.close = df.close.values.astype('float64')\n",
    "df.open = df.open.values.astype('float64')\n",
    "df.volume = df.volume.values.astype('float64')\n",
    "df.amount = df.money.values.astype('float64')\n",
    "\n",
    "df.tail(3), df.head(3), df.isnull().any(), df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate The 1 Minute Rate of Return for Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-07T02:28:43.930647Z",
     "start_time": "2022-09-07T02:28:43.901169Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>money</th>\n",
       "      <th>1_min_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-06-21 13:55:00</td>\n",
       "      <td>6928.0</td>\n",
       "      <td>6934.0</td>\n",
       "      <td>6926.0</td>\n",
       "      <td>6932.0</td>\n",
       "      <td>2053.0</td>\n",
       "      <td>71143293.0</td>\n",
       "      <td>0.000577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-06-21 13:56:00</td>\n",
       "      <td>6932.0</td>\n",
       "      <td>6934.0</td>\n",
       "      <td>6926.0</td>\n",
       "      <td>6926.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>27922527.0</td>\n",
       "      <td>-0.000866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-06-21 13:57:00</td>\n",
       "      <td>6926.0</td>\n",
       "      <td>6932.0</td>\n",
       "      <td>6926.0</td>\n",
       "      <td>6930.0</td>\n",
       "      <td>678.0</td>\n",
       "      <td>23490440.0</td>\n",
       "      <td>0.000578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-06-21 13:58:00</td>\n",
       "      <td>6930.0</td>\n",
       "      <td>6934.0</td>\n",
       "      <td>6930.0</td>\n",
       "      <td>6932.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>24469960.0</td>\n",
       "      <td>0.000289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-06-21 13:59:00</td>\n",
       "      <td>6932.0</td>\n",
       "      <td>6944.0</td>\n",
       "      <td>6932.0</td>\n",
       "      <td>6936.0</td>\n",
       "      <td>4663.0</td>\n",
       "      <td>161743927.0</td>\n",
       "      <td>0.000577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date    open    high     low   close  volume        money  \\\n",
       "0 2022-06-21 13:55:00  6928.0  6934.0  6926.0  6932.0  2053.0   71143293.0   \n",
       "1 2022-06-21 13:56:00  6932.0  6934.0  6926.0  6926.0   806.0   27922527.0   \n",
       "2 2022-06-21 13:57:00  6926.0  6932.0  6926.0  6930.0   678.0   23490440.0   \n",
       "3 2022-06-21 13:58:00  6930.0  6934.0  6930.0  6932.0   706.0   24469960.0   \n",
       "4 2022-06-21 13:59:00  6932.0  6944.0  6932.0  6936.0  4663.0  161743927.0   \n",
       "\n",
       "   1_min_return  \n",
       "0      0.000577  \n",
       "1     -0.000866  \n",
       "2      0.000578  \n",
       "3      0.000289  \n",
       "4      0.000577  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['1_min_return'] = df.open.pct_change(1).shift(-1)\n",
    "df = df.dropna()\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Training and Testing Datase# 分割训练和测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-25T08:01:14.543207Z",
     "start_time": "2022-08-25T08:01:14.538340Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# 训练集占比75%，测试集占比25%\n",
    "train_test_split_date = datetime.strptime('2022-7-14', \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-25T08:01:16.892136Z",
     "start_time": "2022-08-25T08:01:16.857558Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train_data=df[(df.date<train_test_split_date)]\n",
    "train_data=train_data.reset_index(drop=True)\n",
    "\n",
    "train_data.head(3), train_data.tail(3), train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-25T08:01:19.570094Z",
     "start_time": "2022-08-25T08:01:19.553629Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "test_data=df[(df.date>=train_test_split_date)]\n",
    "test_data=test_data.reset_index(drop=True)\n",
    "\n",
    "test_data.head(3), test_data.shape, test_data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-25T08:01:21.631315Z",
     "start_time": "2022-08-25T08:01:21.617577Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "X_train = train_data.drop(columns=['date','1_min_return']).to_numpy()\n",
    "y_train = train_data['1_min_return'].values\n",
    "\n",
    "X_train, X_train.shape, y_train, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-25T08:01:23.716034Z",
     "start_time": "2022-08-25T08:01:23.704295Z"
    },
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test = test_data.drop(columns=['date', '1_min_return']).to_numpy()\n",
    "y_test = test_data['1_min_return'].values\n",
    "\n",
    "X_test, X_test.shape, y_test, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add More Functions and a Customized Backtest Fitness Function for GPlearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-25T08:01:26.925202Z",
     "start_time": "2022-08-25T08:01:26.724293Z"
    },
    "code_folding": [
     1,
     22,
     43,
     64,
     77,
     91,
     104,
     119,
     134,
     147,
     162,
     175,
     190,
     193,
     209,
     219,
     229,
     241,
     254,
     275,
     288,
     301,
     314,
     328,
     341,
     354,
     368,
     381,
     392,
     403,
     414,
     417,
     421,
     424,
     427,
     433
    ],
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "init_function = ['add', 'sub', 'mul', 'div','sqrt', 'log','inv','sin','max','min']\n",
    "def _ts_beta(x1, x2, n):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        try:\n",
    "            if n[0] == n[1] and n[1] == n[2]:\n",
    "                u'''need：(list1,list2,number)  return：number\n",
    "                前 n 期样本 A 对 B 做回归所得回归系数'''\n",
    "                list1 = x1.flatten().tolist()\n",
    "                list2 = x2.flatten().tolist()\n",
    "                n = int(n[0])\n",
    "                list1 = np.array(list1[-n-1:]).reshape(-1, 1)\n",
    "                list2 = np.array(list2[-n-1:]).reshape(-1, 1)\n",
    "                linreg = LinearRegression()\n",
    "                model = linreg.fit(list1, list2)\n",
    "                res = linreg.coef_.tolist()[0]\n",
    "                res = np.array(res+[0]*(len(x1)-len(linreg.coef_))).flatten()\n",
    "                return res\n",
    "            else:\n",
    "                return np.zeros(x1.shape[0])\n",
    "        except:\n",
    "            return np.zeros(x1.shape[0])\n",
    "        \n",
    "def _ts_resid(x1, x2, n):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        try:\n",
    "            if n[0] == n[1] and n[1] == n[2]:\n",
    "                u'''need：(list1,list2,number)  return：number\n",
    "                前 n 期样本 A 对 B 做回归所得的残差'''\n",
    "                list1 = x1.flatten().tolist()\n",
    "                list2 = x2.flatten().tolist()\n",
    "                n = int(n[0])\n",
    "                list1 = np.array(list1[-n-1:]).reshape(-1, 1)\n",
    "                list2 = np.array(list2[-n-1:]).reshape(-1, 1)\n",
    "                linreg = LinearRegression()\n",
    "                model = linreg.fit(list1, list2)\n",
    "                res = list(linreg.intercept_)\n",
    "                res = np.array(res+[0]*(len(x1)-len([linreg.intercept_]))).flatten()\n",
    "                return res\n",
    "            else:\n",
    "                return np.zeros(x1.shape[0])\n",
    "        except:\n",
    "            return np.zeros(x1.shape[0])\n",
    "        \n",
    "def _corr(data1,data2,n):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        try:\n",
    "            if n[0] == n[1] and n[1] ==n[2]:\n",
    "                window  = n[0]\n",
    "                x1 = pd.Series(data1.flatten())\n",
    "                x2 = pd.Series(data2.flatten())\n",
    "                df = pd.concat([x1,x2],axis=1)\n",
    "                temp = pd.Series()\n",
    "                for i in range(len(df)):\n",
    "                    if i<=window-2:\n",
    "                        temp[str(i)] = np.nan\n",
    "                    else:\n",
    "                        df2 = df.iloc[i-window+1:i,:]\n",
    "                        temp[str(i)] = df2.corr('spearman').iloc[1,0]\n",
    "                return np.nan_to_num(temp)\n",
    "            else:\n",
    "                return np.zeros(data1.shape[0])\n",
    "        except:\n",
    "            return np.zeros(data1.shape[0])\n",
    "        \n",
    "def SEQUENCE(n):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        try:\n",
    "            if n[0] == n[1] and n[1] == n[2]:\n",
    "                a = n[0]\n",
    "                res = np.array(list(range(1, a+1)))\n",
    "                res = res.tolist()+[0]*(len(n)-len(res))\n",
    "                return np.array(res).flatten()\n",
    "            else:\n",
    "                return np.zeros(n.shape[0])\n",
    "        except:\n",
    "            return np.zeros(n.shape[0])\n",
    "\n",
    "def _ts_prod(x, n):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        try:\n",
    "            if n[0] == n[1] and n[1] == n[2]:\n",
    "                x = pd.Series(x.flatten())\n",
    "                n = n[0]\n",
    "                res = x.prod(min_count=n)\n",
    "                res = np.array([res]+[0]*(len(x)-1))\n",
    "                return res\n",
    "            else:\n",
    "                return np.zeros(x.shape[0]) \n",
    "        except:\n",
    "            return np.zeros(data1.shape[0]) \n",
    "        \n",
    "def _ts_cov(x,y,window):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        try:\n",
    "            if n[0] == n[1] and n1[1] == n[2]:\n",
    "                x = pd.Series(x.flatten())\n",
    "                y = pd.Series(y.flatten())\n",
    "                res = x.rolling(window).cov(y).fillna(0).values\n",
    "                return res\n",
    "            else:\n",
    "                return np.zeros(x.shape[0]) \n",
    "        except:\n",
    "            return np.zeros(x.shape[0])\n",
    "\n",
    "def _ts_lowday(x1, n1):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        try:\n",
    "            if n1[0] == n1[1] and n1[1] == n1[2]:\n",
    "                '''need：(list,number)  return：number\n",
    "                计算 A 前 n 期时间序列中最小值距离当前时点的间隔'''\n",
    "                n = int(n1[0])\n",
    "                x = x1.flatten().tolist()    \n",
    "                lowday = n-x[-n:].index(min(list(x)[-n:]))-1\n",
    "                return np.array([lowday]+[0]*(len(x)-1))\n",
    "            else:\n",
    "                return np.zeros(x1.shape[0]) \n",
    "        except:\n",
    "            return np.zeros(x1.shape[0]) \n",
    "        \n",
    "def _ts_highday(x1, n1):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        try:\n",
    "            if n1[0] == n1[1] and n1[1] == n1[2]:\n",
    "                u'''need：(list,number)  return：number\n",
    "                计算 A 前 n 期时间序列中最大值距离当前时点的间隔'''\n",
    "                n = int(n1[0])\n",
    "                x = x1.flatten().tolist()\n",
    "                highday = n-x[-n:].index(max(list(x)[-n:]))-1\n",
    "                return np.array([highday]+[0]*(len(x)-1))\n",
    "            else:\n",
    "                return np.zeros(x1.shape[0]) \n",
    "        except:\n",
    "            return np.zeros(x1.shape[0]) \n",
    "        \n",
    "def _ts_adv(x,d):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        try:\n",
    "            if d[0] == d[1] and d[1] == d[2]:\n",
    "                d = int(d[0])\n",
    "                reslist(map(lambda t: np.mean(x.flatten()[t:t+20]),range(len(x.flatten())-d+1)))\n",
    "                res = res[numpy.isneginf(res)] = 0\n",
    "                return np.array(res)\n",
    "            else:\n",
    "                return np.zeros(x.shape[0])\n",
    "        except:\n",
    "            return np.zeros(x.shape[0])\n",
    "            \n",
    "def _ts_wma(x1,d):\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            try:\n",
    "                if d[0] == d[1] and d[1] == d[2]:\n",
    "                    d = int(d[0])\n",
    "                    x1 = pd.Series(x1.flatten())\n",
    "                    weights = np.arange(1,d+1)\n",
    "                    wma = x1.rolling(d).apply(lambda prices: np.dot(prices, weights)/weights.sum(), raw=True)\n",
    "                    wma = wma.fillna(0).values\n",
    "                    return wma\n",
    "                else:\n",
    "                    return np.zeros(x1.shape[0])\n",
    "            except:\n",
    "                return np.zeros(x1.shape[0])\n",
    "\n",
    "def _ts_mean(X, d):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        try:\n",
    "            if d[0] == d[1] and d[1] == d[2]:\n",
    "                X = pd.Series(X.flatten())\n",
    "                res = X.rolling(window=d[0]).mean()\n",
    "                res = res.fillna(0).values\n",
    "                return res\n",
    "            else:\n",
    "                return np.zeros(X.shape[0])\n",
    "        except:\n",
    "            return np.zeros(X.shape[0])\n",
    "\n",
    "def _decay_linear(data1,n):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        try:\n",
    "            if n[0] == n[1] and n[1] == n[2]:\n",
    "                n = int(n[0])\n",
    "                w = np.arange(1,n+1)\n",
    "                w = w[::-1]\n",
    "                w = np.array(w)/np.sum(w)\n",
    "                res = list(map(lambda t: np.sum(np.multiply(np.array(data1.flatten()[t:t+n]),w)),range(len(data1.flatten())-n+1)))\n",
    "                return np.array(res).flatten()\n",
    "            else:\n",
    "                return np.zeros(data1.shape[0])\n",
    "        except:\n",
    "            return np.zeros(data1.shape[0])\n",
    "\n",
    "def _abs(x1):\n",
    "    return abs(x1.flatten())\n",
    "\n",
    "def _ts_abs(data1, n):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        try:\n",
    "            if n[0] == n[1] and n[1] == n[2]:\n",
    "                window = int(n[0])\n",
    "                x1 = data1.flatten()\n",
    "                temp1 = x1[-window:]\n",
    "                temp1 = np.abs(temp1)\n",
    "                temp2 = x1[:-window]\n",
    "                result = np.append(temp2,temp1)\n",
    "                return result\n",
    "            else:\n",
    "                return np.zeros(data1.shape[0])\n",
    "        except:\n",
    "            return np.zeros(data1.shape[0]) \n",
    "\n",
    "def _ts_scale(data1, n):\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            try:\n",
    "                if n[0] == n[1] and n[1] == n[2]:\n",
    "                    return (int(n[0])*x1 / np.nansum(np.abs(data1.flatten())))\n",
    "                else:\n",
    "                    return np.zeros(data1.shape[0])\n",
    "            except:\n",
    "                return np.zeros(data1.shape[0])\n",
    "            \n",
    "def _signedpower(data1, n):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        try:\n",
    "            if n[0] == n[1] and n[1] == n[2]:\n",
    "                return np.sign(data1.flatten()) * np.power(np.abs(data1.flatten()), int(n[0]))\n",
    "            else:\n",
    "                return np.zeros(data1.shape[0])\n",
    "        except:\n",
    "            return np.zeros(data1.shape[0]) \n",
    "\n",
    "def _ts_delta(data1,n):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        try:\n",
    "            if n[0] == n[1] and n[1] == n[2]:\n",
    "                a1 = data1-pd.Series(data1.flatten()).shift(periods=int(n[0]))\n",
    "                a1 = a1.fillna(0).values\n",
    "                return a1\n",
    "            else:\n",
    "                return np.zeros(data1.shape[0])\n",
    "        except:\n",
    "            return np.zeros(data1.shape[0]) \n",
    "\n",
    "def _ts_delay(data1,n):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        try:\n",
    "            if n[0] == n[1] and n[1] == n[2]:\n",
    "                a1 = pd.Series(data1.flatten())\n",
    "                a1 = a1.shift(periods=int(n[0]))\n",
    "                a1 = a1.fillna(0).values\n",
    "                return a1\n",
    "            else:\n",
    "                return np.zeros(data1.shape[0])\n",
    "        except:\n",
    "            return np.zeros(data1.shape[0]) \n",
    "\n",
    "def _ts_corr(data1,data2,n):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        try:\n",
    "            if n[0] == n[1] and n[1] ==n[2]:\n",
    "                window = int(n[0])\n",
    "                x1 = pd.Series(data1.flatten())\n",
    "                x2 = pd.Series(data2.flatten())\n",
    "                df = pd.concat([x1,x2],axis=1)\n",
    "                temp = pd.Series()\n",
    "                for i in range(len(df)):\n",
    "                    if i<=window-2:\n",
    "                        temp[str(i)] = np.nan\n",
    "                    else:\n",
    "                        df2 = df.iloc[i-window+1:i,:]\n",
    "                        temp[str(i)] = df2.corr('spearman').iloc[1,0]\n",
    "                return np.nan_to_num(temp)\n",
    "            else:\n",
    "                return np.zeros(data1.shape[0])\n",
    "        except:\n",
    "            return np.zeros(data1.shape[0]) \n",
    "\n",
    "def _ts_sum(data,n):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        try:\n",
    "            if n[0] == n[1] and n[1] ==n[2]:\n",
    "                window = int(n[0])\n",
    "                value = np.array(pd.Series(data.flatten()).rolling(window).sum().tolist())\n",
    "                value = np.nan_to_num(value)\n",
    "                return value\n",
    "            else:\n",
    "                return np.zeros(data.shape[0])\n",
    "        except:\n",
    "            return np.zeros(data.shape[0])\n",
    "        \n",
    "def _ts_sma(data,n):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):   \n",
    "        try:\n",
    "            if n[0] == n[1] and n[1] ==n[2]:\n",
    "                window = int(n[0])\n",
    "                value = np.array(pd.Series(data.flatten()).rolling(window).mean().tolist())\n",
    "                value = np.nan_to_num(value)\n",
    "                return value\n",
    "            else:\n",
    "                return np.zeros(data.shape[0])\n",
    "        except:\n",
    "            return np.zeros(data.shape[0])\n",
    "\n",
    "def _ts_stddev(data,n):   \n",
    "    with np.errstate(divide='ignore', invalid='ignore'): \n",
    "        try:\n",
    "            if n[0] == n[1] and n[1] ==n[2]:\n",
    "                window = int(n[0])\n",
    "                value = np.array(pd.Series(data.flatten()).rolling(window).std().tolist())\n",
    "                value = np.nan_to_num(value)\n",
    "                return value\n",
    "            else:\n",
    "                return np.zeros(data.shape[0])\n",
    "        except:\n",
    "            return np.zeros(data.shape[0])\n",
    "\n",
    "def _ts_rank(x1,n):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        try:\n",
    "            if n[0] == n[1] and n[1] ==n[2]:\n",
    "                n = int(n[0])\n",
    "                x2 = pd.Series(x1.flatten()[-n:])\n",
    "                res = x2.rank(pct=True).values\n",
    "                res = res.tolist()+[0]*(x1.shape[0] - res.shape[0])\n",
    "                return np.array(res)\n",
    "            else:\n",
    "                return np.zeros(x1.shape[0]) \n",
    "        except:\n",
    "            return np.zeros(x1.shape[0]) \n",
    "        \n",
    "def _ts_argmin(data,n):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        try:\n",
    "            if n[0] == n[1] and n[1] ==n[2]:\n",
    "                window = int(n[0])\n",
    "                value = pd.Series(data.flatten()).rolling(window).apply(np.argmin) + 1 \n",
    "                value = np.nan_to_num(value)\n",
    "                return value\n",
    "            else:\n",
    "                return np.zeros(data.shape[0])  \n",
    "        except:\n",
    "            return np.zeros(data.shape[0])  \n",
    "\n",
    "def _ts_argmax(data,n):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        try:\n",
    "            if n[0] == n[1] and n[1] ==n[2]:\n",
    "                window = int(n[0])\n",
    "                value = pd.Series(data.flatten()).rolling(window).apply(np.argmax) + 1 \n",
    "                value = np.nan_to_num(value)\n",
    "                return value\n",
    "            else:\n",
    "                return np.zeros(data.shape[0])\n",
    "        except:\n",
    "            return np.zeros(data.shape[0]) \n",
    "        \n",
    "def _ts_min(data,n):\n",
    "    import numpy as np\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        try:\n",
    "            if n[0] == n[1] and n[1] ==n[2]:\n",
    "                window = int(n[0])\n",
    "                value = np.array(pd.Series(data.flatten()).rolling(window).min().tolist())\n",
    "                value = np.nan_to_num(value)\n",
    "                return value\n",
    "            else:\n",
    "                return np.zeros(data.shape[0])\n",
    "        except:\n",
    "            return np.zeros(data.shape[0])\n",
    "\n",
    "def _ts_max(data,n):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        try:\n",
    "            if n[0] == n[1] and n[1] ==n[2]:\n",
    "                window = int(n[0])\n",
    "                value = np.array(pd.Series(data.flatten()).rolling(window).max().tolist())\n",
    "                value = np.nan_to_num(value)\n",
    "                return value\n",
    "            else:\n",
    "                return np.zeros(data.shape[0])\n",
    "        except:\n",
    "            return np.zeros(data.shape[0])\n",
    "@jit\n",
    "def _beta(x1, x2):\n",
    "    list1 = x1.flatten().tolist()\n",
    "    list2 = x2.flatten().tolist()\n",
    "    list1 = np.array(list1).reshape(-1, 1)\n",
    "    list2 = np.array(list2).reshape(-1, 1)\n",
    "    linreg = LinearRegression()\n",
    "    model = linreg.fit(list1, list2)\n",
    "    res = linreg.coef_.tolist()[0]\n",
    "    res = np.array(res+[0]*(len(x1)-len(linreg.coef_))).flatten()\n",
    "    return res\n",
    "\n",
    "def _resid(x1, x2):\n",
    "    list1 = x1.flatten().tolist()\n",
    "    list2 = x2.flatten().tolist()\n",
    "    list1 = np.array(list1).reshape(-1, 1)\n",
    "    list2 = np.array(list2).reshape(-1, 1)\n",
    "    linreg = LinearRegression()\n",
    "    model = linreg.fit(list1, list2)\n",
    "    res = linreg.coef_.tolist()[0]\n",
    "    res = np.array(res+[0]*(len(x1)-len(linreg.intercept_))).flatten()\n",
    "    return res \n",
    "\n",
    "def _beta(x1, x2):\n",
    "    list1 = x1.flatten().tolist()\n",
    "    list2 = x2.flatten().tolist()\n",
    "    list1 = np.array(list1).reshape(-1, 1)\n",
    "    list2 = np.array(list2).reshape(-1, 1)\n",
    "    linreg = LinearRegression()\n",
    "    model = linreg.fit(list1, list2)\n",
    "    res = linreg.coef_.tolist()[0]\n",
    "    res = np.array(res+[0]*(len(x1)-len(linreg.coef_))).flatten()\n",
    "    return res\n",
    "\n",
    "def _abs(x1):\n",
    "    return abs(x1.flatten())\n",
    "\n",
    "def _rank(x1):\n",
    "    x1 = pd.Series(x1.flatten())\n",
    "    return x1.rank(pct=True).values\n",
    "        \n",
    "def _cube(data):\n",
    "    return np.square(data.flatten())*data.flatten()\n",
    "\n",
    "def _square(data):\n",
    "    return np.square(data.flatten())\n",
    "\n",
    "def _ts_argmaxmin(data,n):\n",
    "    try:\n",
    "        return _ts_argmax(data,n) - _ts_argmin(data,n)\n",
    "    except:\n",
    "        return np.zeros(data.shape[0])\n",
    "\n",
    "def _my_metric_backtest(y, y_pred, w):\n",
    "    pred = pd.Series(y_pred.flatten()).fillna(0)\n",
    "    y = pd.Series(y.flatten()).fillna(0)\n",
    "    short_profit = 0\n",
    "    long_profit = 0\n",
    "    held_long = 0\n",
    "    held_short = 0\n",
    "    profit = []\n",
    "    profit_temp = 0\n",
    "    \n",
    "    for i in range(len(pred)):\n",
    "        current_pred = pred.iloc[i]\n",
    "        current_return = y.iloc[i]\n",
    "        #open long\n",
    "        if current_pred>=0.75 and held_long==0 and held_short==0:\n",
    "            held_long = 1\n",
    "            held_short = 0\n",
    "            long_profit += current_return\n",
    "                    \n",
    "        #hold long\n",
    "        elif current_pred>=0.75 and held_long==1 and held_short==0:\n",
    "            held_long = 1\n",
    "            held_short = 0\n",
    "            long_profit += current_return\n",
    "            \n",
    "        #open long and close short\n",
    "        elif current_pred>=0.75 and held_long==0 and held_short==1:\n",
    "            #close short and record profit\n",
    "            held_long = 1\n",
    "            held_short = 0\n",
    "            short_profit += (-current_return)\n",
    "            profit.append(short_profit)\n",
    "            #open long\n",
    "            long_profit += current_return\n",
    "                    \n",
    "        #open short\n",
    "        elif current_pred<=-0.75and held_long==0 and held_short==0:\n",
    "            held_long = 0\n",
    "            held_short = 1\n",
    "            short_profit += (-current_return)\n",
    "            \n",
    "        #keep short\n",
    "        elif current_pred<=-0.75 and held_long==0 and held_short==1:\n",
    "            held_long = 0\n",
    "            held_short = 1\n",
    "            short_profit += (-current_return)\n",
    "  \n",
    "        #close long and open short\n",
    "        elif current_pred <=-0.75 and held_long==1 and held_short==0:\n",
    "            #close long\n",
    "            held_long = 0\n",
    "            held_short = 1\n",
    "            long_profit += current_return\n",
    "            profit.append(long_profit)\n",
    "            #open short\n",
    "            short_profit += (-current_return)\n",
    "                    \n",
    "        #closeout long \n",
    "        elif current_pred<0.75 and current_pred>-0.75 and held_long==1 and held_short==0:\n",
    "            held_long = 0\n",
    "            held_short = 0\n",
    "            long_profit += current_return\n",
    "            profit.append(long_profit)      \n",
    "            \n",
    "        #closeout short    \n",
    "        elif current_pred<0.75 and current_pred>-0.75 and held_long==0 and held_short==1:\n",
    "            held_long = 0\n",
    "            held_short = 0\n",
    "            short_profit += (-current_return)\n",
    "            profit.append(short_profit)\n",
    "    try:        \n",
    "        total_return = profit[-1]\n",
    "    except:\n",
    "        total_return = 0\n",
    "        \n",
    "    result = total_return\n",
    "    \n",
    "    del pred\n",
    "    del y\n",
    "    del short_profit\n",
    "    del long_profit\n",
    "    del held_long\n",
    "    del held_short\n",
    "    del profit\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activate The Customized Fuctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-25T08:01:29.960684Z",
     "start_time": "2022-08-25T08:01:29.863086Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "ts_beta = make_function(function = _ts_beta, name='ts_beta', arity=3, wrap=False)\n",
    "beta = make_function(function = _beta, name='beta', arity=2, wrap=False)\n",
    "ts_resid = make_function(function = _ts_resid, name='ts_resid', arity=3, wrap=False)\n",
    "resid = make_function(function = _resid, name='resid', arity=2, wrap=False)\n",
    "corr = make_function(function = _corr, name='corr', arity=3, wrap=False) \n",
    "SEQUENCE = make_function(function=SEQUENCE, name='SEQUENCE', arity=1, wrap=False) \n",
    "ts_cov = make_function(function=_ts_cov, name='ts_cov', arity=3, wrap=False) \n",
    "ts_lowday = make_function(function=_ts_lowday, name='ts_lowday', arity=2, wrap=False) \n",
    "ts_highday = make_function(function=_ts_highday, name='ts_highday', arity=2, wrap=False) \n",
    "ts_adv = make_function(function=_ts_adv, name='ts_adv', arity=2, wrap=False)  \n",
    "ts_wma = make_function(function=_ts_wma, name='ts_wma', arity=2, wrap=False)       \n",
    "ts_mean = make_function(function=_ts_mean, name='ts_mean', arity=2, wrap=False) \n",
    "decay_linear = make_function(function=_decay_linear, name='decay_linear', arity=2, wrap=False) \n",
    "_abs = make_function(function=_abs, name='_abs', arity=1, wrap=False) \n",
    "ts_abs = make_function(function=_ts_abs, name='ts_abs', arity=2, wrap=False) \n",
    "rank = make_function(function=_rank, name='rank', arity=1, wrap=False) \n",
    "ts_scale = make_function(function=_ts_scale, name='ts_scale', arity=2, wrap=False) \n",
    "ts_delta = make_function(function=_ts_delta, name='ts_delta', arity=2, wrap=False) \n",
    "ts_delay = make_function(function=_ts_delay, name='ts_delay', arity=2, wrap=False)  \n",
    "ts_sma = make_function(function=_ts_sma, name='ts_sma', arity=2, wrap=False)     \n",
    "ts_std = make_function(function=_ts_stddev, name='ts_std', arity=2, wrap=False)     \n",
    "ts_rank = make_function(function=_ts_rank, name='ts_rank', arity=2, wrap=False)\n",
    "ts_stddev = make_function(function=_ts_stddev, name='ts_stddev', arity=2, wrap=False)\n",
    "ts_sum = make_function(function=_ts_sum, name='ts_sum', arity=2, wrap=False)\n",
    "ts_corr = make_function(function=_ts_corr, name='ts_corr', arity=3, wrap=False)\n",
    "ts_min = make_function(function=_ts_min, name='ts_min', arity=2, wrap=False)\n",
    "cube = make_function(function=_cube, name='cube', arity=1, wrap=False)\n",
    "square = make_function(function=_square, name='square', arity=1, wrap=False)\n",
    "ts_argmaxmin = make_function(function=_ts_argmaxmin, name='ts_argmaxmin', arity=2, wrap=False)\n",
    "ts_argmax = make_function(function=_ts_argmax, name='ts_argmax', arity=2)\n",
    "ts_argmin = make_function(function=_ts_argmin, name='ts_argmin', arity=2, wrap=False)\n",
    "ts_min = make_function(function=_ts_min, name='ts_min', arity=2, wrap=False)\n",
    "ts_max = make_function(function=_ts_max, name='ts_max', arity=2, wrap=False)\n",
    "#decay_linear,ts_corr(replaced by corr),\n",
    "user_function = [SEQUENCE, ts_cov, ts_lowday, ts_highday, ts_adv, ts_wma, ts_mean, _abs, rank, ts_scale, ts_delta, ts_delay, \n",
    "                 ts_sma, ts_std, ts_rank, ts_sum, corr, ts_min, cube, square, ts_argmaxmin, ts_argmax, ts_argmin, ts_min, ts_max, ts_beta,\n",
    "                beta, ts_resid, resid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activate The Customized Fitness Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-25T08:01:31.532952Z",
     "start_time": "2022-08-25T08:01:31.527932Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "my_metric = make_fitness(function=_my_metric_backtest, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-25T08:02:32.757737Z",
     "start_time": "2022-08-25T08:01:35.665889Z"
    },
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "function_set = init_function + user_function\n",
    "population_size = 2000\n",
    "generations = 10\n",
    "random_state= 5\n",
    "est_gp = SymbolicTransformer(\n",
    "                            feature_names=fields, \n",
    "                            function_set=function_set,\n",
    "                            generations=generations,\n",
    "                            metric=my_metric,\n",
    "                            population_size=population_size,\n",
    "                            tournament_size=30, \n",
    "                            random_state=random_state,\n",
    "                            verbose=2, \n",
    "                            hall_of_fame=100,\n",
    "                            parsimony_coefficient=0.0001,\n",
    "                            p_crossover = 0.4,\n",
    "                            p_subtree_mutation = 0.01,\n",
    "                            p_hoist_mutation = 0,\n",
    "                            p_point_mutation = 0.01,\n",
    "                            p_point_replace = 0.4,\n",
    "                            n_jobs = 8)\n",
    "     \n",
    "X_train = np.nan_to_num(X_train)\n",
    "y_train = np.nan_to_num(y_train)\n",
    "est_gp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resulting Alpha Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T04:11:59.659567Z",
     "start_time": "2021-09-26T04:11:59.644568Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "best_programs = est_gp._best_programs\n",
    "best_programs_dict = {}\n",
    "\n",
    "for p in best_programs:\n",
    "    factor_name = 'alpha_' + str(best_programs.index(p) + 1)\n",
    "    best_programs_dict[factor_name] = {'fitness':p.fitness_, 'expression':str(p), 'depth':p.depth_, 'length':p.length_}\n",
    "     \n",
    "best_programs_dict = pd.DataFrame(best_programs_dict).T\n",
    "best_programs_dict = best_programs_dict.sort_values(by='fitness')\n",
    "best_programs_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T04:12:06.269981Z",
     "start_time": "2021-09-26T04:12:06.012909Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "filename = 'gplearn_PTA_1min_factors.pkl'\n",
    "with open(filename, 'wb') as f:\n",
    "     cloudpickle.dump(est_gp, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read The Model File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T04:12:07.035997Z",
     "start_time": "2021-09-26T04:12:06.983811Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "filename = 'gplearn_PTA_1min_factors.pkl'\n",
    "with open(filename, 'rb') as f:\n",
    "    est_gp = cloudpickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T04:12:07.530387Z",
     "start_time": "2021-09-26T04:12:07.519388Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "best_programs = est_gp._best_programs\n",
    "best_programs_dict = {}\n",
    "\n",
    "for p in best_programs:\n",
    "    factor_name = 'alpha_' + str(best_programs.index(p) + 1)\n",
    "    best_programs_dict[factor_name] = {'fitness':p.fitness_, 'expression':str(p), 'depth':p.depth_, 'length':p.length_}\n",
    "     \n",
    "best_programs_dict = pd.DataFrame(best_programs_dict).T\n",
    "best_programs_dict = best_programs_dict.sort_values(by='fitness')\n",
    "best_programs_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize The Alpha Factor Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T04:12:11.459831Z",
     "start_time": "2021-09-26T04:12:11.230868Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def alpha_factor_graph(num):\n",
    "    # 打印指定num的表达式图\n",
    "\n",
    "    factor = best_programs[num-1]\n",
    "    print(factor)\n",
    "    print('fitness: {0}, depth: {1}, length: {2}'.format(factor.fitness_, factor.depth_, factor.length_))\n",
    "\n",
    "    dot_data = factor.export_graphviz()\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    graph.render('images/alpha_factor_graph', format='png', cleanup=True)\n",
    "    \n",
    "    return graph\n",
    "\n",
    "graph1 = alpha_factor_graph(1)\n",
    "graph1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T04:12:11.645879Z",
     "start_time": "2021-09-26T04:12:11.642879Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "factor = best_programs[0]\n",
    "print(factor)\n",
    "print('fitness: {0}, depth: {1}, length: {2}'.format(factor.fitness_, factor.depth_, factor.length_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alpha Factor Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 因子回测函数 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T04:12:14.143970Z",
     "start_time": "2021-09-26T04:12:14.128971Z"
    },
    "code_folding": [
     1
    ],
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def _factor_backtest(factor_perd, market_price):\n",
    "    pred = pd.Series(factor_perd.flatten()).fillna(0)\n",
    "    evaluation = []\n",
    "    slippage = 4\n",
    "    shares = 25\n",
    "    comission = 0.00025\n",
    "     \n",
    "    backtest_data = market_price\n",
    "    trades = pred\n",
    "\n",
    "    short_open = 0\n",
    "    long_open = 0\n",
    "    held_long = 0\n",
    "    held_short = 0\n",
    "    profit = []\n",
    "    profit_temp = 0\n",
    "    initial_assets = shares*max(backtest_data.open.values)\n",
    "    initial_cash = shares*max(backtest_data.open.values)\n",
    "    net_worth = [initial_cash]\n",
    "    \n",
    "    for i in range(len(trades)):\n",
    "        current_pred = trades.iloc[i]\n",
    "        current_close = backtest_data.iloc[i].open.astype('float')\n",
    "        #open long\n",
    "        if current_pred>=0.75 and held_long==0 and held_short==0:\n",
    "            held_long = 1\n",
    "            held_short = 0\n",
    "            long_open = current_close+slippage\n",
    "            short_open = 0\n",
    "            #print('open long')\n",
    "                    \n",
    "        #hold long\n",
    "        elif current_pred>=0.75 and held_long==1 and held_short==0:\n",
    "            #print('hold long')\n",
    "            pass\n",
    "                \n",
    "            #open long and close short\n",
    "        elif current_pred>=0.75 and held_long==0 and held_short==1:\n",
    "            held_long = 1\n",
    "            #close short and calculate profit\n",
    "            held_short = 0\n",
    "            profit_temp = (short_open-(current_close+slippage))*shares*(1-comission)\n",
    "            initial_cash += profit_temp\n",
    "            profit.append(profit_temp)\n",
    "            net_worth.append(initial_cash)\n",
    "            #open long\n",
    "            short_open = 0\n",
    "            long_open = current_close+slippage\n",
    "            #print('open long and close short')\n",
    "                    \n",
    "        #open short\n",
    "        elif current_pred<=-0.75and held_long==0 and held_short==0:\n",
    "            held_long = 0\n",
    "            held_short = 1\n",
    "            long_open = long_open\n",
    "            short_open = current_close+slippage\n",
    "            profit = profit\n",
    "            #print('open short')\n",
    "            \n",
    "        #keep short\n",
    "        elif current_pred<=-0.75 and held_long==0 and held_short==1:\n",
    "            #print('keep short')\n",
    "            pass\n",
    "                \n",
    "        #close long and open short\n",
    "        elif current_pred <=-0.75 and held_long==1 and held_short==0:\n",
    "            #close long\n",
    "            held_long = 0\n",
    "            held_short = 1\n",
    "            profit_temp = ((current_close-slippage)-long_open)*shares*(1-comission)\n",
    "            initial_cash += profit_temp\n",
    "            profit.append(profit_temp)\n",
    "            net_worth.append(initial_cash)\n",
    "            #open short\n",
    "            long_open = 0\n",
    "            short_open = current_close-slippage\n",
    "            profit = profit\n",
    "            #print('close long and open short')\n",
    "                    \n",
    "        #closeout long\n",
    "        elif current_pred<0.75 and current_pred>-0.75 and held_long==1 and held_short==0:\n",
    "            held_long = 0\n",
    "            held_short = 0\n",
    "            profit_temp = ((current_close-slippage)-long_open)*shares*(1-comission)\n",
    "            initial_cash += profit_temp\n",
    "            profit.append(profit_temp)\n",
    "            net_worth.append(initial_cash)\n",
    "            short_open = 0\n",
    "            long_open = 0\n",
    "            #print('closeout long')        \n",
    "            \n",
    "        #closeout short    \n",
    "        elif current_pred<0.75 and current_pred>-0.75 and held_long==0 and held_short==1:\n",
    "            held_long = 0\n",
    "            held_short = 0\n",
    "            profit_temp = (short_open-(current_close+slippage))*shares*(1-comission)\n",
    "            initial_cash += profit_temp\n",
    "            profit.append(profit_temp)\n",
    "            net_worth.append(initial_cash)\n",
    "            short_open = 0\n",
    "            long_open = 0\n",
    "            #print('closeout short')\n",
    "            \n",
    "    total_return = (initial_cash-initial_assets)/initial_assets\n",
    "    print('总收益率', total_return)\n",
    "    shaprpe_df = pd.Series(profit)\n",
    "    sharpe_temp = (shaprpe_df - shaprpe_df.shift(1))/shaprpe_df.shift(1)\n",
    "    sharpe = sharpe_temp.mean()/sharpe_temp.std()*np.sqrt(len(profit))\n",
    "          \n",
    "    a = np.maximum.accumulate(net_worth)\n",
    "    l = np.argmax((np.maximum.accumulate(net_worth) - net_worth)/np.maximum.accumulate(net_worth))\n",
    "    k = np.argmax(net_worth[:l])\n",
    "    max_draw = (net_worth[k] - net_worth[l])/(net_worth[l]) \n",
    "    print('最大回撤', max_draw)        \n",
    "        \n",
    "    win_count = 0\n",
    "    loss_count = 0\n",
    "    initial_profit = 0\n",
    "    for i in range(len(net_worth)):\n",
    "        current_profit = net_worth[i]\n",
    "        if i==0:\n",
    "            if current_profit > initial_assets:\n",
    "                win_count += 1\n",
    "            else:\n",
    "                loss_count += 1\n",
    "        else:\n",
    "            last_profit = net_worth[i-1]\n",
    "            if current_profit > last_profit:\n",
    "                win_count += 1\n",
    "            else:\n",
    "                loss_count += 1\n",
    "    win_rate = win_count/len(net_worth)\n",
    "    print('胜率', win_rate)\n",
    "    \n",
    "    total_gain = 0\n",
    "    total_loss = 0\n",
    "    for i in range(len(profit)):\n",
    "        if profit[i] >0:\n",
    "            total_gain += profit[i]\n",
    "        else:\n",
    "            total_loss += profit[i]\n",
    "    gain_loss_ratio = (total_gain/win_count)/(abs(total_loss)/loss_count)\n",
    "    print('盈亏比', gain_loss_ratio)\n",
    "    \n",
    "    result = total_return*np.nan_to_num(sharpe,nan=1)*win_rate*gain_loss_ratio*(1-max_draw)\n",
    "    \n",
    "    x = np.array(net_worth).reshape(len(net_worth),)\n",
    "    y = np.arange(len(net_worth))\n",
    "    \n",
    "    plt.rcParams['font.sans-serif'] = ['KaiTi'] # 指定默认字体\n",
    "    plt.rcParams['axes.unicode_minus'] = False # 解决保存图像是负号'-'显示为方块的问题\n",
    "    fig = plt.figure(figsize=(16,9))\n",
    "    plt.plot(y, x)\n",
    "    plt.title('因子资金曲线',fontsize=20)\n",
    "    plt.xlabel('交易次数',fontsize=20)\n",
    "    plt.ylabel('账户净值',fontsize=20)\n",
    "    plt.show()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Alpha Factor Backtest Results (In-Sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T04:12:15.887437Z",
     "start_time": "2021-09-26T04:12:15.082423Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "factors_pred = est_gp.transform(X_train)\n",
    "factors_pred.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T04:12:16.026423Z",
     "start_time": "2021-09-26T04:12:15.981422Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pred_data = pd.DataFrame(factors_pred).T.T\n",
    "pred_data, pred_data.iloc[:,[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alpha Factor Backtest Results (In-Sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T04:13:20.214386Z",
     "start_time": "2021-09-26T04:12:16.722885Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#Total Rate of Return: 总收益率\n",
    "#Max drawdown: 最大回撤\n",
    "#Wining Rate: 胜率\n",
    "#Win-loss ratio:盈亏比\n",
    "#Graph Title: Factor Backtest Account Networth cruve\n",
    "#Graph X Axis: Number of Trades\n",
    "#Graph y Axis: Account Networth\n",
    "_factor_backtest(pred_data.iloc[:,[0]].values, train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Alpha Factor Backtest Results (Out-of-Sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T04:13:20.477401Z",
     "start_time": "2021-09-26T04:13:20.339386Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "factors_pred_1 = est_gp.transform(X_test)\n",
    "factors_pred_1.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T04:13:20.647386Z",
     "start_time": "2021-09-26T04:13:20.618386Z"
    },
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_data_1 = pd.DataFrame(factors_pred_1).T.T\n",
    "pred_data_1, pred_data_1.iloc[:,[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alpha Factor Backtest Results (Out-of-Sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-26T04:13:30.897424Z",
     "start_time": "2021-09-26T04:13:20.786386Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#Total Rate of Return: 总收益率\n",
    "#Max drawdown: 最大回撤\n",
    "#Wining Rate: 胜率\n",
    "#Win-loss ratio:盈亏比\n",
    "#Graph Title: Factor Backtest Account Networth cruve\n",
    "#Graph X Axis: Number of Trades\n",
    "#Graph y Axis: Account Networth\n",
    "_factor_backtest(pred_data_1.iloc[:,[0]].values, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "MarkDown菜单",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}